{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CLIMB-TRE","text":""},{"location":"#introduction","title":"Introduction","text":"<p>The CLIMB Trusted Research Environment (CLIMB-TRE) project provides tools with which users can upload metagenomics data, with metadata, and analyse them on CLIMB.</p> <p>This site documents how to use the CLIMB-TRE tools and is distinct from more general documentation on using CLIMB. Read further for general information on how to upload or analyse data.</p>"},{"location":"#contents","title":"Contents","text":""},{"location":"#getting-started","title":"Getting Started","text":"<p>How to Upload Data Learn how to upload data to CLIMB-TRE.</p> <p>Checking Submission Results Learn how to check the status of data submitted to CLIMB-TRE.</p> <p>Analysing Data Get started analysing data within CLIMB-TRE using Onyx.</p> <p>Further Examples Further project-specific analysis examples using Onyx.</p>"},{"location":"#project-specifications","title":"Project Specifications","text":"<p>Common Structure Learn more about required files, naming conventions and processing requirements common to all projects.</p>"},{"location":"#project-list","title":"Project List","text":"Project Description Uploader Specification Analysis Specification Template CSV mSCAPE Metagenomics Surveillance Collaboration and Analysis Programme Uploader Specification Analysis Specification mscape-template.csv PATH-SAFE Pathogen Surveillance in Agriculture, Food and Environment Uploader Specification Analysis Specification pathsafe-template.csv synthSCAPE Synthetic dataset for mSCAPE Uploader Specification Analysis Specification synthscape-template.csv openMGS Open Meta-Genomic Surveillance Uploader Specification Analysis Specification openmgs-template.csv"},{"location":"analyse/","title":"Analysing data","text":""},{"location":"analyse/#overview","title":"Overview","text":"<p>Once data and metadata have been ingested into the Onyx database, you can query it using the Onyx client, which provides a command line interface (CLI) and Python API.  This short example demonstrates a few principal functions.  More are described in the <code>onyx-client</code> documentation.</p> <p>This guide also assumes that you're using a Notebook Server on CLIMB, so that once installed, the Onyx client will automatically be configured.</p>"},{"location":"analyse/#onyx-client-basics","title":"Onyx client basics","text":"<p>First, let's install the Onyx client, which is available through the conda-forge package <code>climb-onyx-client</code> and can thus be installed with <code>conda</code>.  As advised in the CLIMB docs on installing software, you should install the client in a new Conda environment. I'll name my environment <code>onyx</code> and install <code>climb-onyx-client</code>, as well as <code>ipykernel</code> (so that the client is available in my Jupyter Notebooks). <pre><code>jovyan:~$ conda create -n onyx ipykernel climb-onyx-client\n</code></pre> Let's activate this environment. <pre><code>jovyan:~$ conda activate onyx\n</code></pre> On Bryn's Notebook Servers, the client will automatically be configured. Try running the command-line client with <pre><code>(onyx) jovyan:~$ onyx\n</code></pre> This should show you some options and commands that are available. Have a look at your own profile with <pre><code>(onyx) jovyan:~$ onyx profile\n</code></pre> and which projects you have access to with <pre><code>(onyx) jovyan:~$ onyx projects\n</code></pre> You should see <code>mscape</code> listed.</p>"},{"location":"analyse/#querying-data","title":"Querying data","text":"<p>As an example task, we'll see if we can find any sequencing data performed for ZymoBIOMICS sources.  These are designed with  a particular specification of DNA from eight bacteria and two yeasts.  We can use these to see if our protocol correctly recovers the DNA fractions. I.e. if our protocol is biased.</p> <p>From the command line, the main route to querying Onyx is via the <code>filter</code> command. On its own, this queries the database with no filters.  The command <pre><code>(onyx) jovyan:~$ onyx filter mscape\n</code></pre> will produce tens of thousands of lines of JSON, so let's not do that just yet.  To first see which fields are available in the database, we can use <pre><code>(onyx) jovyan:~$ onyx fields mscape\n...\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 extraction_enrichment_protocol \u2502 optional \u2502 text              \u2502 Details of nucleic acid extraction and optional enrichment steps.            \u2502                                                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n...\n</code></pre> Let's search the database for entries with <code>zymo</code> (case-insensitive) in this field. <pre><code>(onyx) jovyan:~$ onyx filter mscape --field extraction_enrichment_protocol.icontains=zymo\n...\n</code></pre> That should return JSON data for a few entries.  You may wish to format the data as CSV or TSV with <code>--format csv</code> or <code>--format tsv</code>, respectively.</p>"},{"location":"analyse/#inspecting-some-pipeline-output-on-the-command-line","title":"Inspecting some pipeline output on the command line","text":"<p>When data is ingested into Onyx, a taxonomic classification is automatically run. The last part of the JSON data is usually some of this, in JSON format. The complete reports can be found in the S3 buckets given in the <code>'taxon_report'</code> field.  You can find this in the output you've already produced or modify the <code>filter</code> command to only request them using the <code>--include</code> flag. e.g. <pre><code>(onyx) jovyan:~$ onyx filter mscape --field extraction_enrichment_protocol.icontains=zymo --include=taxon_reports\n[\n    {\n        \"taxon_reports\": \"s3://mscape-published-taxon-reports/C-FDE50853AD/\"\n    },\n    {\n        \"taxon_reports\": \"s3://mscape-published-taxon-reports/C-04F4495068/\"\n    }\n]\n</code></pre> Multiple fields can be requested with the <code>--include</code> flag e.g. <pre><code>(onyx) jovyan:~$ onyx filter mscape --field extraction_enrichment_protocol.icontains=zymo --include climb_id,taxon_reports\n[\n    {\n        \"climb_id\": \"C-FDE50853AD\",\n        \"taxon_reports\": \"s3://mscape-published-taxon-reports/C-FDE50853AD/\"\n    },\n    {\n        \"climb_id\": \"C-04F4495068\",\n        \"taxon_reports\": \"s3://mscape-published-taxon-reports/C-04F4495068/\"\n    }\n]\n</code></pre> You can conversely exclude individual fields using the <code>--exclude</code> flag in the same way.</p> <p>Either way, you now have the location of the taxonomy reports.  Let's have a look with <code>s3cmd</code>. <pre><code>(onyx) jovyan:~$ s3cmd ls s3://mscape-published-taxon-reports/C-FDE50853AD/\n2023-11-10 12:56   146K  s3://mscape-published-taxon-reports/C-FDE50853AD/PlusPF.kraken.json\n2023-11-10 12:56     2G  s3://mscape-published-taxon-reports/C-FDE50853AD/PlusPF.kraken_assignments.tsv\n2023-11-10 12:56   193K  s3://mscape-published-taxon-reports/C-FDE50853AD/PlusPF.kraken_report.txt\n</code></pre> The plain text report is what we're after, so let's download that with <code>s3cmd</code>: <pre><code>(onyx) jovyan:~$ s3cmd get s3://mscape-published-taxon-reports/C-FDE50853AD/PlusPF.kraken_report.txt\ndownload: 's3://mscape-published-taxon-reports/C-FDE50853AD/PlusPF.kraken_report.txt' -&gt; './PlusPF.kraken_report.txt'  [1 of 1]\n 197750 of 197750   100% in    0s     3.79 MB/s  done\n</code></pre></p> <p>If you've never seen one of these reports before, it's worth having a quick look with a tool like <code>less</code> or by opening it using the JupyterLab file browser.  For reference, it's worth showing the header <pre><code>(onyx) jovyan:~$ head -n 1 PlusPF.kraken_report.txt\n% of Seqs       Clades  Taxonomies      Rank    Taxonomy ID     Scientific Name\n</code></pre> The Zymo sample is prepared with 12% Bacillus subtilis.  Let's see how much was actually reported in the results: <pre><code>(onyx) jovyan:~$ grep \"Bacillus subtilis\" PlusPF.kraken_report.txt\n 20.30  435278  1452    G1      653685                    Bacillus subtilis group\n  0.12  2624    1952    S       1423                        Bacillus subtilis\n  0.03  565     242     S1      135461                        Bacillus subtilis subsp. subtilis\n  0.01  108     108     S2      1404258                         Bacillus subtilis subsp. subtilis str. OH 131.1\n  ...\n</code></pre> Looks like 20.3%, though classified under Bacillus subtilis \"subgroup\", rather than Bacillus subtilis, which reportedly only comprises 0.12% of the sample. Most of that 20.3% is under Bacillus spizizenii.</p> <p>An important detail here is that the fraction reported in this output is not calculated in the same way as what's used in the reference values (12% for bacteria; 2% for yeasts). Let's make a fairer comparison using the JSON taxonomic data.</p>"},{"location":"analyse/#working-with-database-output-in-python","title":"Working with database output in Python","text":"<p>To fairly compare the taxonomic data with the reference values in the Zymo community, we need to know the proportions of gDNA, so we need to compute the number of base pairs that were assigned to each taxon. Let's make this comparison in Python using the Onyx client's Python API.</p> <p>Let's first run the same query for the Zymo data.  We'll follow the examples in the Onyx documentation and run the query in a context manager. <pre><code>import os\nfrom onyx import OnyxConfig, OnyxEnv, OnyxClient\n\nconfig = OnyxConfig(\n    domain=os.environ[OnyxEnv.DOMAIN],\n    token=os.environ[OnyxEnv.TOKEN],\n)\n\nwith OnyxClient(config) as client:\n    records = list(client.filter(\n        \"mscape\",\n        fields={\n            \"extraction_enrichment_protocol__icontains\": \"zymo\",\n        },\n    ))\n</code></pre> We've wrapped the <code>filter</code> call in a <code>list</code> because otherwise we get a generator.</p> <p>If you want to inspect the data, it's a bit easier to read if formatted with indentation, which can be done using the standard <code>json.dumps</code> function: <pre><code>import json\nprint(json.dumps(records[0], indent=2))  # show first record\n</code></pre> In each record, the <code>'taxa_files'</code> key gives us a list of dictionaries that each has a number of reads and a mean length, the product of which is the total number of base pairs that were read for that taxon.  A simple first step is to convert the taxonomic data (for the first record) into a Pandas DataFrame with <pre><code>import pandas as pd\n\ndf = pd.DataFrame(records[0]['taxa_files'])\n</code></pre> We also need to drop a few lower-level taxa that are already accounted for in higher ones. e.g. the reads for Bacillus spizizenii TU-B-10 are among the reads counted for Bacillus spizizenii.  A quick way of doing this is by selecting the rows that have only two words in their names. <pre><code>df = df.loc[df['human_readable'].apply(lambda name: len(name.split()) == 2)]\n</code></pre> Now, let's add columns for the total number of base pairs associated with each taxon and what proportion that is of the total. <pre><code>df['gDNA'] = df['n_reads']*df['mean_len']\ndf['proportion'] = df['gDNA']/df['gDNA'].sum()\n</code></pre> Finally, let's make a rough plot with a black dashed line at 12%. <pre><code>import matplotlib.pyplot as plt\n\nplt.plot(df['human_readable'], df['proportion']*100, 'o')\nplt.axhline(12, c='k', ls='--');\nplt.xticks(rotation=22.5, ha='right');\n</code></pre></p> <p></p> <p>There are some clear discrepancies\u2014Pseudomonas aeruginosa is underreported and Bacillus spizizenii is overreported\u2014but this matches results by e.g. Nicholls et al. (2019).</p> <p>This short example is intended as a basic demonstration of what's possible in CLIMB-TRE.  We're always interested to hear more examples of research questions that CLIMB-TRE can answer, so let us know if you have an example that could be included as a guide for others.</p>"},{"location":"common/","title":"Project specification structure","text":""},{"location":"common/#overview","title":"Overview","text":"<p>All projects on CLIMB-TRE are specified in the same way.</p>"},{"location":"common/#files-to-be-provided","title":"Files to be provided","text":"<p>These are the files that must be uploaded (usually some sequencing reads and a metadata file). Submissions without the correct number of files provided will be considered incomplete and will not be processed.</p>"},{"location":"common/#file-naming-convention","title":"File naming convention","text":"<p>This is the convention to which the provided file names must adhere.</p> <p>Each of the files to be provided will use the same basename followed by specified extensions (e.g. for data versus metadata).  The basename for each file is usually several fields separated by a fixed number of stops/periods (<code>.</code>).</p> <p>The set of valid characters is usually limited to letters, numbers, hyphens (<code>-</code>) and underscores (<code>_</code>) but this will be specified. Filenames containing forbidden characters or extensions will not be processed.</p>"},{"location":"common/#file-processing-requirements","title":"File processing requirements","text":""},{"location":"common/#fastq","title":"FASTQ","text":"<ul> <li>Must be gzipped.</li> <li>Must adhere to the FASTQ format.</li> </ul>"},{"location":"common/#csv","title":"CSV","text":"<ul> <li>Must be a plain text file with comma-delimited data.</li> <li>Must contain two rows: the first will contain the column names and the second will contain the data.</li> <li>Must have column names that match the specification exactly.</li> <li>Must not have missing data for required fields.</li> <li>Must not have invalid data (e.g. <code>\"N/A\"</code>) to circumvent missing data checks.</li> <li>Must not contain metadata that contradicts the file name.</li> <li>Must use the latest version of the metadata specification.</li> </ul>"},{"location":"common/#metadata-specification","title":"Metadata specification","text":"<p>The metadata for each project is specified in tables detailing required fields (which must not be empty) and optional fields (which can be left empty).</p>"},{"location":"common/#project-upload-buckets","title":"Project upload buckets","text":"<p>Files should be uploaded to S3 buckets hosted at the <code>s3.climb.ac.uk</code> endpoint. </p> <p>The bucket names are a combination of:</p> <ul> <li>Project (e.g. <code>mscape</code>).</li> <li>Site code (e.g. <code>bham</code>).</li> <li>Platform (e.g. <code>illumina</code>).</li> <li>A flag that indicates a test (<code>test</code>) or production (<code>prod</code>) submission.</li> </ul> <p>All files must be placed in the root directory of the submission buckets. Any S3 URI containing a directory will be ignored.</p>"},{"location":"mscape-analysis/","title":"mSCAPE Analysis Specification","text":""},{"location":"mscape-analysis/#analysis-fields","title":"Analysis fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>published_date</code> <code>date</code> The date the object was published in Onyx. \u2022 Output format: <code>iso-8601</code> <code>site</code> <code>choice</code> The site or sequencing centre providing the data. \u2022 Choices: <code>bham</code>, <code>cuh</code>, <code>gosh</code>, <code>gstt</code>, <code>nuth</code>, <code>public</code>, <code>ripl</code>, <code>ucl</code>, <code>uclh</code>, <code>uhs</code>, <code>ukhsa</code>, <code>ukhsabris</code>, <code>ukhsamanc</code>, <code>wtsi</code> <code>climb_id</code> <code>text</code> Unique identifier for a project record in Onyx. <code>biosample_id</code> <code>text</code> The sequencing provider's identifier for a sample. <code>biosample_source_id</code> <code>text</code> Unique identifier for an individual to permit multiple samples from the same individual to be linked. <code>run_id</code> <code>text</code> Unique identifier assigned to the run by the sequencing instrument. <code>platform</code> <code>choice</code> The platform used to sequence the data. \u2022 Choices: <code>illumina</code>, <code>illumina.se</code>, <code>ont</code> <code>input_type</code> <code>choice</code> The type of input sequenced. \u2022 Choices: <code>community_standard</code>, <code>negative_control</code>, <code>positive_control</code>, <code>specimen</code>, <code>validation_material</code> <code>specimen_type_details</code> <code>choice</code> Named control or standard for specimens. \u2022 Choices: <code>asymptomatic</code>, <code>respiratory_infection</code> <code>control_type_details</code> <code>choice</code> Named control or standard for positive and negative controls. \u2022 Choices: <code>NIBSC_11/242</code>, <code>NIBSC_20/170</code>, <code>bacillus_ms2phage</code>, <code>resp_matrix_mc110</code>, <code>water_extraction_control</code>, <code>zepto_rp2.1</code>, <code>zymo-mc_D6300</code> <code>sample_source</code> <code>choice</code> The source from which the sample was collected. \u2022 Choices: <code>blood</code>, <code>environment</code>, <code>faecal</code>, <code>lower_respiratory</code>, <code>nose_and_throat</code>, <code>other</code>, <code>plasma</code>, <code>pleural_fluid</code>, <code>stool</code>, <code>tissue</code>, <code>upper_respiratory</code>, <code>urine</code> <code>sample_type</code> <code>choice</code> The type of sampling method used. \u2022 Choices: <code>aspirate</code>, <code>bal</code>, <code>biopsy</code>, <code>other</code>, <code>sputum</code>, <code>swab</code> <code>spike_in</code> <code>choice</code> The type of spike-in used in the run. \u2022 Choices: <code>ERCC-RNA_4456740</code>, <code>bacillus_ms2phage</code>, <code>ms2-phage</code>, <code>none</code>, <code>phix</code>, <code>tobacco_mosaic_virus</code>, <code>zymo_D6320</code>, <code>zymo_D6321</code> <code>spike_in_result</code> <code>choice</code> Result assigned by scylla for the provided spike-in. \u2022 Choices: <code>fail</code>, <code>partial</code>, <code>pass</code> <code>collection_date</code> <code>date</code> The date the sample was collected. \u2022 Output format: <code>YYYY-MM-DD</code> <code>received_date</code> <code>date</code> The date the sample was received by the sequencing centre (if collection_date unavailable). \u2022 Output format: <code>YYYY-MM-DD</code> <code>is_approximate_date</code> <code>bool</code> The date is approximate e.g. the sample is from a public repository and it is unclear whether the date corresponds to collection or publishing. <code>batch_id</code> <code>text</code> Used to identify samples prepared in the same laboratory batch (e.g. extraction, library and/or sequencing). <code>study_id</code> <code>text</code> Used to identify study or if NHS residual sample. <code>study_centre_id</code> <code>text</code> Used to identify sequencing centre. <code>sequence_purpose</code> <code>choice</code> Used to differentiate between clinical or research studies. \u2022 Choices: <code>clinical</code>, <code>research</code> <code>governance_status</code> <code>choice</code> Did the patient consent to their sample being used for research purposes or not. \u2022 Choices: <code>consented_for_research</code>, <code>no_consent_for_research</code>, <code>open</code> <code>iso_country</code> <code>choice</code> Country that the sample was collected in, using ISO-3166-1 alpha-2 codes (https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2), unless within United Kingdom. If so, use ISO-3166-2:GB (https://en.wikipedia.org/wiki/ISO_3166-2:GB). \u2022 Choices: <code>AD</code>, <code>AE</code>, <code>AF</code>, <code>AG</code>, <code>AI</code>, <code>AL</code>, <code>AM</code>, <code>AO</code>, <code>AQ</code>, <code>AR</code>, <code>AS</code>, <code>AT</code>, <code>AU</code>, <code>AW</code>, <code>AX</code>, <code>AZ</code>, <code>BA</code>, <code>BB</code>, <code>BD</code>, <code>BE</code>, ... <code>iso_region</code> <code>choice</code> Region that the sample was collected in, using the second level subdivision codes of ISO-3166-2:GB (https://www.iso.org/obp/ui/#iso:code:3166:GB). \u2022 Choices: <code>GB-ABC</code>, <code>GB-ABD</code>, <code>GB-ABE</code>, <code>GB-AGB</code>, <code>GB-AGY</code>, <code>GB-AND</code>, <code>GB-ANN</code>, <code>GB-ANS</code>, <code>GB-BAS</code>, <code>GB-BBD</code>, <code>GB-BCP</code>, <code>GB-BDF</code>, <code>GB-BDG</code>, <code>GB-BEN</code>, <code>GB-BEX</code>, <code>GB-BFS</code>, <code>GB-BGE</code>, <code>GB-BGW</code>, <code>GB-BIR</code>, <code>GB-BKM</code>, ... <code>extraction_enrichment_protocol</code> <code>text</code> Details of nucleic acid extraction and optional enrichment steps. <code>library_protocol</code> <code>text</code> Details of sequencing library construction. <code>sequencing_protocol</code> <code>text</code> Details of sequencing. <code>protocol_arm</code> <code>choice</code> Used to indicate arm for protocols which have separate arms for bacterial and viral nucleic acids. \u2022 Choices: <code>bacterial</code>, <code>viral</code> <code>bioinformatics_protocol</code> <code>text</code> Detail of initial bioinformatics protocol, for example versions of basecalling software and models used, any read quality filtering/trimming employed. <code>dehumanisation_protocol</code> <code>text</code> Details of bioinformatics method used for human read removal. <code>is_public_dataset</code> <code>bool</code> The sample is from a public dataset. Please only set this after it has been made public. <code>public_database_name</code> <code>choice</code> The public repository where the data is. \u2022 Choices: <code>ENA</code>, <code>SRA</code> <code>public_database_accession</code> <code>text</code> The accession for the data in the public database. <code>ingest_report</code> <code>text</code> HTML report summarising the read profile and taxa identified. <code>taxon_reports</code> <code>text</code> Folder of all classification output files. <code>human_filtered_reads_1</code> <code>text</code> Compressed FASTQ of input reads that have been filtered for human reads. <code>human_filtered_reads_2</code> <code>text</code> Compressed FASTQ of input reads that have been filtered for human reads. <code>unclassified_reads_1</code> <code>text</code> Compressed FASTQ of input reads which could not be classified. <code>unclassified_reads_2</code> <code>text</code> Compressed FASTQ of input reads which could not be classified. <code>viral_reads_1</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral. <code>viral_reads_2</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral. <code>viral_and_unclassified_reads_1</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral or were unclassified. <code>viral_and_unclassified_reads_2</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral or were unclassified. <code>total_bases</code> <code>integer</code> Total number of bases in the input FASTQ file(s), before any filtering. <code>classifier</code> <code>choice</code> The classifier used. \u2022 Choices: <code>Kraken2</code> <code>classifier_version</code> <code>text</code> Version of the classifier used. <code>classifier_db</code> <code>choice</code> Database used for read classification. \u2022 Choices: <code>PlusPF</code> <code>classifier_db_date</code> <code>date</code> Date classifier database was produced. \u2022 Output format: <code>YYYY-MM-DD</code> <code>ncbi_taxonomy_date</code> <code>date</code> Date that the NCBI taxonomy dump was produced. \u2022 Output format: <code>YYYY-MM-DD</code> <code>scylla_version</code> <code>text</code> Version of the scylla pipeline used. <code>chimera_bam</code> <code>text</code> BAM file of the human filtered read fraction aligned to the zeus database. <code>is_chimera_published</code> <code>bool</code> Whether chimera has been run on this record or not. <code>alignment_db_version</code> <code>text</code> Version of the Zeus database used. <code>sylph_db_version</code> <code>text</code> Sylph database version utilised to produce Sylph classifications. <code>taxa_files</code> <code>relation</code> Table of all species level taxa extracted by the Scylla ingest pipeline. <code>taxa_files.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>taxa_files.human_readable</code> <code>text</code> A human readable name for the taxa. <code>taxa_files.n_reads</code> <code>integer</code> The number of reads extracted for the taxa. <code>taxa_files.total_bases</code> <code>integer</code> Total number of bases extracted for the taxa. <code>taxa_files.avg_quality</code> <code>decimal</code> The mean quality of reads extracted for the taxa. <code>taxa_files.mean_len</code> <code>decimal</code> The mean length of reads extracted for the taxa. <code>taxa_files.rank</code> <code>choice</code> The rank of the taxa. \u2022 Choices: <code>C</code>, <code>D</code>, <code>F</code>, <code>G</code>, <code>K</code>, <code>O</code>, <code>P</code>, <code>R</code>, <code>S</code>, <code>U</code> <code>taxa_files.fastq_1</code> <code>text</code> Compressed FASTQ of extracted reads for the taxa. <code>taxa_files.fastq_2</code> <code>text</code> Compressed FASTQ of extracted reads for the taxa. <code>classifier_calls</code> <code>relation</code> Table summarising the NCBI taxonomy ids, counts and ranks of all taxa found by the classifier during the Scylla ingest pipeline. <code>classifier_calls.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>classifier_calls.human_readable</code> <code>text</code> A human readable name for the taxa. <code>classifier_calls.percentage</code> <code>decimal</code> The percentage of the (dehumanised) sample that the taxa represents. <code>classifier_calls.count_descendants</code> <code>integer</code> The number of reads mapping to this taxa and all descendant taxa. <code>classifier_calls.count_direct</code> <code>integer</code> The number of reads mapping directly to the taxa. <code>classifier_calls.rank</code> <code>choice</code> The rank of the taxa. \u2022 Choices: <code>C</code>, <code>D</code>, <code>F</code>, <code>G</code>, <code>K</code>, <code>O</code>, <code>P</code>, <code>R</code>, <code>S</code>, <code>U</code> <code>classifier_calls.raw_rank</code> <code>text</code> The rank of the taxa including an intermediate grading. <code>classifier_calls.is_spike_in</code> <code>bool</code> The taxa is a spike-in. <code>spike_in_info</code> <code>relation</code> Table containing results found for the provided spike-in. <code>spike_in_info.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>spike_in_info.human_readable</code> <code>text</code> A human readable name for the taxa. <code>spike_in_info.reference_header</code> <code>text</code> Reference header for the individual sequence within the provided spike-in. <code>spike_in_info.mapped_count</code> <code>integer</code> Number of reads which aligned to a reference sequence for the provided spike-in. <code>alignment_results</code> <code>relation</code> Table containing alignment results from the viral alignment stage of the CLIMB-TRE/chimera pipeline. <code>alignment_results.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>alignment_results.human_readable</code> <code>text</code> Human readable scientific name for the taxa. <code>alignment_results.unique_accession</code> <code>text</code> Unique reference identifier in the alignment database (everything prior to the first whitespace in the FASTA header). <code>alignment_results.accession_description</code> <code>text</code> The comment for the reference sequence within the alignment database. <code>alignment_results.sequence_length</code> <code>integer</code> Length of the reference sequence in the alignment database. <code>alignment_results.evenness_value</code> <code>integer</code> A percentage indicating how evenly read depths are distributed throughout the reference, with 0 being completely uneven, and 100 being perfectly even. Taken from https://academic.oup.com/nar/article/38/10/e116/2902812, under the \u201cCalculation of evenness score\u201d section, and calculated here: https://github.com/CLIMB-TRE/chimera/blob/dca3cacb949dabc902d0a12e5d11d36c6ac555fd/bin/generate_alignment_report.py#L102. <code>alignment_results.mean_depth</code> <code>integer</code> Mean of all depth values across the alignment reference. <code>alignment_results.coverage_1x</code> <code>integer</code> Percentage of the reference sequence covered with a depth of at least 1x. <code>alignment_results.coverage_10x</code> <code>integer</code> Percentage of the reference covered with a depth of at least 10x. <code>alignment_results.mapped_reads</code> <code>integer</code> Total number of reads mapped to the alignment reference. <code>alignment_results.uniquely_mapped_reads</code> <code>integer</code> Total number of reads which uniquely map to each reference sequence, calculated for each reference sequence here: https://github.com/CLIMB-TRE/chimera/blob/bca6fe6fe293f8e56d9e70627a846dda6f3d886a/bin/generate_alignment_report.py#L59-L82. <code>alignment_results.mapped_bases</code> <code>integer</code> Approximation for the total number of bases mapped to the alignment reference, calculated from the length of the reference sequence multiplied by the mean depth of alignments to that reference. <code>alignment_results.mean_read_identity</code> <code>decimal</code> Mean of read identities across all alignments. Can be considered an approximation for identity of the source genome with the reference sequence. Calculated for each read here: https://github.com/CLIMB-TRE/chimera/blob/dca3cacb949dabc902d0a12e5d11d36c6ac555fd/bin/generate_alignment_report.py#L58 <code>alignment_results.read_duplication_rate</code> <code>decimal</code> What proportion of the reads start and end in the same alignment reference position as at least one other read within the alignment. Calculated here: https://github.com/CLIMB-TRE/chimera/blob/dca3cacb949dabc902d0a12e5d11d36c6ac555fd/bin/generate_alignment_report.py#L76-L83 <code>alignment_results.forward_proportion</code> <code>decimal</code> Proportion of reads which aligned to the forward strand. Between 0 and 1, with 0 indicating all reads aligned to the reverse strand, 1 the opposite. True hits should be close to 0.5 for this value for any reasonable mean depth. <code>alignment_results.mean_alignment_length</code> <code>decimal</code> Mean length of all alignments to the reference - different to mean read length aligned to the reference, since it only considers the aligned section of the reads. <code>sylph_results</code> <code>relation</code> Table containing sylph results from the Sylph classification stage of the CLIMB-TRE/chimera pipeline. <code>sylph_results.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>sylph_results.human_readable</code> <code>text</code> Human readable scientific name for the taxa. <code>sylph_results.gtdb_taxon_string</code> <code>text</code> Description of the taxonomic placement of the source contig within the Sylph database using GTDBs taxon string format. <code>sylph_results.gtdb_assembly_id</code> <code>text</code> Assembly ID (often genbank accession) for the contig within the sylph database, taken from GTDB. <code>sylph_results.gtdb_contig_header</code> <code>text</code> From the origin FASTA record header as it appears in GTDB. Identical to 'Contig_name' field in sylph profile output. <code>sylph_results.taxonomic_abundance</code> <code>decimal</code> Normalized taxonomic abundance as a percentage. Identical to 'Taxonomic_abundance' in sylph profile output. <code>sylph_results.sequence_abundance</code> <code>decimal</code> Normalized sequence abundance as a percentage. Identical to 'Sequence_abundance' in sylph profile output. <code>sylph_results.adjusted_ani</code> <code>decimal</code> If coverage adjustment is possible (cov is &lt; 3x cov): returns coverage-adjusted ANI (Average Nucleotide Identity). If coverage is too low/high: returns naive_ani. Identical to 'Adjusted_ANI' in sylph profile output. <code>sylph_results.ani_confidence_interval</code> <code>text</code> [5%,95%] confidence intervals. If coverage adjustment is possible: float-float e.g. 98.52-99.55. If coverage is too low/high: NA-NA is given. Identical to 'ANI_5-95_percentile' field in sylph profile output. <code>sylph_results.effective_coverage</code> <code>decimal</code> Estimated '\u03bbeff' value, true value is not calculated, this is estimated based on kmers. More information is available in the sylph paper: https://www.nature.com/articles/s41587-024-02412-y. If coverage adjustment is possible, lambda estimate is given. Identical to 'Eff_cov' field in sylph profile output. <code>sylph_results.effective_coverage_confidence_interval</code> <code>text</code> [5%, 95%] confidence intervals for lambda. Same format rules as 'ani_confidence_interval'. Identical to 'Lambda_5-95_percentile' field in sylph profile output. <code>sylph_results.median_kmer_cov</code> <code>integer</code> Median k-mer multiplicity for k-mers with &gt;= 1 multiplicity. Identical to 'Median_cov' field in sylph profile output. <code>sylph_results.mean_kmer_cov</code> <code>decimal</code> Mean k-mer multiplicity for k-mers with &gt;= 1 multiplicity. Identical to 'Mean_cov_geq1' field in sylph profile output. <code>sylph_results.containment_index</code> <code>text</code> int/int showing the containment index (number of k-mers found in sample divided by total k-mers), e.g. 959/1053. Identical to 'Containment_ind' field in sylph profile output. <code>sylph_results.naive_ani</code> <code>decimal</code> Containment ANI without coverage adjustment. Identical to 'Naive_ANI' field in sylph profile output. <code>sylph_results.kmers_reassigned</code> <code>integer</code> The number of k-mers reassigned away from the genome. Identical to 'Kmers_reassigned' field in sylph profile output."},{"location":"mscape-changelog/","title":"mSCAPE Changelog","text":"<p>All notable changes to CLIMB-TRE mSCAPE APIs, data or interchange formats that have impact to users or other pipelines should be documented in this file. Changes described here may only be a subset of all changes to a project as this log concerns itself only with changes that impact how data is provided or consumed by users or other pipelines.</p> <p>The following DIPI projects are routinely using this changelog:</p> <ul> <li><code>Scylla</code> -- ingest analysis pipeline</li> <li><code>Roz</code> -- ingest management</li> <li><code>Onyx</code> -- metadata database</li> <li><code>Onyx-client</code> -- API for interacting with metadata database</li> </ul> <p>The format is based on Keep a Changelog.</p> <p>Issues can be reported to the mSCAPE DIPI group.</p>"},{"location":"mscape-changelog/#2025-10-17","title":"2025-10-17","text":""},{"location":"mscape-changelog/#onyx","title":"Onyx","text":""},{"location":"mscape-changelog/#added","title":"Added","text":""},{"location":"mscape-changelog/#alignment-results","title":"Alignment Results","text":"<ul> <li>Added <code>alignment_results</code> table.</li> <li>Added <code>alignment_results.taxon_id</code> field.</li> <li>Added <code>alignment_results.human_readable</code> field.</li> <li>Added <code>alignment_results.unique_accession</code> field.</li> <li>Added <code>alignment_results.accession_description</code> field.</li> <li>Added <code>alignment_results.sequence_length</code> field.</li> <li>Added <code>alignment_results.evenness_value</code> field.</li> <li>Added <code>alignment_results.mean_depth</code> field.</li> <li>Added <code>alignment_results.coverage_1x</code> field.</li> <li>Added <code>alignment_results.coverage10x</code> field.</li> <li>Added <code>alignment_results.mapped_reads</code> field.</li> <li>Added <code>alignment_results.uniquely_mapped_reads</code> field.</li> <li>Added <code>alignment_results.mapped_bases</code> field.</li> <li>Added <code>alignment_results.mean_read_identity</code> field.</li> <li>Added <code>alignment_results.read_duplication_rate</code> field.</li> <li>Added <code>alignment_results.forward_proportion</code> field.</li> <li>Added <code>alignment_results.mean_alignment_length</code> field.</li> </ul>"},{"location":"mscape-changelog/#sylph-results","title":"Sylph Results","text":"<ul> <li>Added <code>sylph_results</code> table.</li> <li>Added <code>sylph_results.taxon_id</code> field.</li> <li>Added <code>sylph_results.human_readable</code> field.</li> <li>Added <code>sylph_results.gtdb_taxon_string</code> field.</li> <li>Added <code>sylph_results.gtdb_assembly_id</code> field.</li> <li>Added <code>sylph_results.gtdb_contig_header</code> field.</li> <li>Added <code>sylph_results.taxonomic_abundance</code> field.</li> <li>Added <code>sylph_results.sequence_abundance</code> field.</li> <li>Added <code>sylph_results.adjusted_ani</code> field.</li> <li>Added <code>sylph_results.ani_confidence_interval</code> field.</li> <li>Added <code>sylph_results.effective_coverage</code> field.</li> <li>Added <code>sylph_results.effective_coverage_confidence_interval</code> field.</li> <li>Added <code>sylph_results.median_kmer_cov</code> field.</li> <li>Added <code>sylph_results.mean_kmer_cov</code> field.</li> <li>Added <code>sylph_results.containment_index</code> field.</li> <li>Added <code>sylph_results.naive_ani</code> field.</li> <li>Added <code>sylph_results.kmers_reassigned</code> field.</li> </ul>"},{"location":"mscape-changelog/#2025-09-15","title":"2025-09-15","text":""},{"location":"mscape-changelog/#onyx_1","title":"Onyx","text":""},{"location":"mscape-changelog/#added_1","title":"Added","text":"<ul> <li>Added <code>ucl</code> (University College London) <code>site</code> option.</li> <li>Added <code>ukhsamanc</code> (UKHSA Manchester Lab) <code>site</code> option.</li> <li>Added <code>ukhsabris</code> (UKHSA Bristol Lab) <code>site</code> option.</li> </ul>"},{"location":"mscape-changelog/#2025-08-13","title":"2025-08-13","text":""},{"location":"mscape-changelog/#onyx_2","title":"Onyx","text":""},{"location":"mscape-changelog/#added_2","title":"Added","text":"<ul> <li>Added <code>control_type_details</code> choice <code>bacillus_ms2phage</code>, constrained by an <code>input_type</code> of <code>positive_control</code>.</li> <li>Added optional choice field <code>protocol_arm</code>, with choices <code>bacterial</code> and <code>viral</code>.</li> </ul>"},{"location":"mscape-changelog/#scylla","title":"Scylla","text":"<p>Release 2.1.0</p>"},{"location":"mscape-changelog/#changed","title":"Changed","text":"<ul> <li>Large speedup of all read extract scripts</li> <li>Per read quality scores are now based on mean rather than median</li> </ul>"},{"location":"mscape-changelog/#2025-08-05","title":"2025-08-05","text":""},{"location":"mscape-changelog/#scylla_1","title":"Scylla","text":"<p>Release 2.0.3</p>"},{"location":"mscape-changelog/#changed_1","title":"Changed","text":"<ul> <li>Resolve missing total_length.json when no taxa files output</li> </ul>"},{"location":"mscape-changelog/#2025-08-05_1","title":"2025-08-05","text":""},{"location":"mscape-changelog/#onyx_3","title":"Onyx","text":""},{"location":"mscape-changelog/#added_3","title":"Added","text":"<ul> <li>Added <code>spike_in</code> option <code>bacillus_ms2phage</code>.</li> </ul>"},{"location":"mscape-changelog/#scylla_2","title":"Scylla","text":"<p>Release 2.0.2</p>"},{"location":"mscape-changelog/#added_4","title":"Added","text":"<ul> <li>Added <code>spike_in</code> option <code>bacillus_ms2phage</code>.</li> </ul>"},{"location":"mscape-changelog/#changed_2","title":"Changed","text":"<ul> <li>Changed reference to --local flag in README/tests for local running to -profile local (can be combined with docker using -profile local,docker)</li> </ul>"},{"location":"mscape-changelog/#2025-07-02","title":"2025-07-02","text":""},{"location":"mscape-changelog/#onyx_4","title":"Onyx","text":""},{"location":"mscape-changelog/#added_5","title":"Added","text":"<ul> <li>Added <code>total_bases</code> field, for recording the number of bases in the input FASTQ file(s), before any filtering.</li> <li>Added <code>taxa_files.total_bases</code> field, for recording the number of bases extracted for a taxa (assignable for each taxa within the <code>taxa_files</code> of a record).</li> </ul>"},{"location":"mscape-changelog/#scylla_3","title":"Scylla","text":"<p>Release 2.0.1</p>"},{"location":"mscape-changelog/#changed_3","title":"Changed","text":"<ul> <li>Change the exitcode for script which checks paired fastq files so that the pipeline doesn't fail loudly with mismatched headers</li> </ul>"},{"location":"mscape-changelog/#2025-05-08","title":"2025-05-08","text":""},{"location":"mscape-changelog/#scylla_4","title":"Scylla","text":"<p>Released version 2.0.0. Given the number of changes, they are grouped by category rather than Added/Changed etc. </p>"},{"location":"mscape-changelog/#hcid-changes","title":"HCID changes","text":"<ul> <li>Add <code>min_coverage</code> parameter to HCID JSON</li> <li>Update references in HCID JSON and reference file</li> <li>Update thresholds for HCID detection</li> <li>Drop requirement for classified reads at taxon/parent level for HCID to be detected (mapping sufficient)</li> <li>Output reads corresponding to HCIDs which have flagged a warning (NEW OUTPUT in <code>qc/&lt;taxid&gt;.reads.fq</code>)</li> <li>Output read stats for HCID reads to the warning JSON (<code>mapped_mean_quality</code> and <code>mapped_mean_length</code>)</li> <li>Add coverage information for HCID found showing how many bases have coverage at each level - in HCID JSON</li> </ul>"},{"location":"mscape-changelog/#extract-taxa-changes","title":"Extract taxa changes","text":"<ul> <li>Reworked code to interact with kraken reports and assignment files during extract steps. Found a bug where some of the counts in the summary had previously been double counted (where both a S and S1 or S2 level taxa were extracted)</li> <li>Extract reads at different levels for different domains as specified by config (<code>F</code> for Viruses, <code>G</code> for everything else)</li> <li>Only extract reads at the specific level, not sublevels (e.g. S not S1 or S2)</li> <li>Add <code>total_len</code> calculated both for input and extracted output files in the summary JSON (NEW OUTPUT <code>qc/total_length.json</code>)</li> <li>Make extraction percentages domain-specific (e.g. 1% of bacterial reads rather than 1% of classified reads) to fix zepto example</li> <li>To extract a taxon, needs to pass count threshold OR the percentage threshold (previously both) and increase the count threshold for bacteria to 500</li> </ul>"},{"location":"mscape-changelog/#workflow-changes","title":"Workflow changes","text":"<ul> <li>Add workflow to reclassify the viral+unclassified fraction with a second database</li> <li>In the process, the parameters associated with kraken databases have been restructured. Replace <code>--k2_host</code> with <code>--kraken_database.default.host</code>, <code>--k2_port</code> with <code>--kraken_database.default.port</code>, <code>--database</code> with <code>--kraken_database.default.path</code> and <code>database_set</code> is now <code>kraken_database.default.name</code>. This allows a second dictionary of kraken parameters for <code>kraken_database.virus</code> to be defined if/when necessary.</li> <li>Add code to merge kraken assignment files, giving preference to second assignment file</li> <li>Add code to update kraken report, giving list of changes made to assignments </li> <li>Add a QC script to check the input file where a single fastq file is provided, so that it can warn if there are duplicate headers. This was seen in some example data and would cause big problems for the viral reclassification step when run, as read names need to be unique. If it finds duplicate/unexpectedly interleaved files, tries to correct them but then exists. The user can try rerunning with the fixed files. I considered silently handling but this approach seemed dangerous.</li> <li>Add messaging if paired reads provided and <code>--paired</code> not.</li> <li>Add a workflow to run modules (use <code>--module &lt;name&gt;</code>) and remove workflow definitions from within these modules</li> <li>Add a warning for incorrect Phred parsing as this is thought to be a resolved issue</li> </ul>"},{"location":"mscape-changelog/#nextflow-changes","title":"Nextflow changes","text":"<ul> <li>set <code>docker.userEmulation   = true</code></li> </ul>"},{"location":"mscape-changelog/#other-changes","title":"Other changes","text":"<ul> <li>Add to README more helpful</li> <li>Review all local test commands and make sure they run as expected.</li> </ul>"},{"location":"mscape-changelog/#2025-03-31","title":"2025-03-31","text":""},{"location":"mscape-changelog/#onyx_5","title":"Onyx","text":""},{"location":"mscape-changelog/#added_6","title":"Added","text":"<ul> <li>Added <code>nuth</code> (Newcastle upon Tyne Hospitals NHS Foundation Trust) as an option in the mSCAPE <code>site</code> field. </li> </ul>"},{"location":"mscape-changelog/#2025-03-06","title":"2025-03-06","text":""},{"location":"mscape-changelog/#all","title":"All","text":"<ul> <li>Start of changelog</li> </ul>"},{"location":"mscape-examples/","title":"Analysis examples for mSCAPE","text":""},{"location":"mscape-examples/#retrieve-all-samples-that-contain-a-particular-taxa-eg-pseudomonas","title":"Retrieve all samples that contain a particular taxa e.g. <code>pseudomonas</code>","text":"<p>This can be done through the CLI:</p> <pre><code>$ onyx filter mscape --field taxa_files.human_readable.icontains=pseudomonas --format csv\n</code></pre> <p>Or through the Python API:</p> <pre><code>import os\nfrom onyx import OnyxConfig, OnyxClient, OnyxEnv, OnyxField\n\nconfig = OnyxConfig(\n    domain=os.environ[OnyxEnv.DOMAIN],\n    token=os.environ[OnyxEnv.TOKEN],\n)\n\nwith OnyxClient(config) as client:\n    # Filter for read sets containing \"pseudomonas\"\n    for metadata in client.query(\n        \"mscape\",\n        query=OnyxField(taxa_files__human_readable__icontains=\"pseudomonas\"),\n    ):\n        # Do analysis here\n        print(\"CLIMB ID:\", metadata[\"climb_id\"])\n        print(\"Published date:\", metadata[\"published_date\"])\n\n        # The query command by default does not return taxonomic information\n        # To get this, we have to call the `get` method and retrieve the samples individually\n        full_metadata = client.get(\"mscape\", metadata[\"climb_id\"])\n\n        # Now we can inspect the taxonomic information for the readset\n        print(\n            \"Number of binned reads:\", len(full_metadata[\"taxa_files\"])\n        )  # etc. Do more analysis\n        print(\"Pseudomonas taxa:\")\n        for taxa in full_metadata[\"taxa_files\"]:\n            if \"pseudomonas\" in taxa[\"human_readable\"].lower():\n                print(\"-\", taxa[\"human_readable\"])\n</code></pre> <p>Example output for this python script: <pre><code>CLIMB ID: C-FE89BACF2D\nPublished date: 2024-02-28\nNumber of binned reads: 3\nPseudomonas taxa:\n- Pseudomonas aeruginosa\n- Pseudomonas aeruginosa PA7\nCLIMB ID: C-470A57DCD0\nPublished date: 2024-02-28\nNumber of binned reads: 8\nPseudomonas taxa:\n- Pseudomonas aeruginosa\n- Pseudomonas aeruginosa PA7\nCLIMB ID: C-FB67513BE0\nPublished date: 2024-02-28\nNumber of binned reads: 4\nPseudomonas taxa:\n- Pseudomonas aeruginosa\nCLIMB ID: C-E49EED98E4\nPublished date: 2024-02-28\nNumber of binned reads: 3\nPseudomonas taxa:\n- Pseudomonas aeruginosa\n- Pseudomonas aeruginosa PA7\n...\n</code></pre></p>"},{"location":"mscape-examples/#get-a-csv-distribution-of-all-binned-taxa-present-in-the-dataset","title":"Get a CSV distribution of all binned taxa present in the dataset","text":"<p>Through the CLI:</p> <pre><code>$ onyx filter mscape --summarise taxa_files.taxon_id,taxa_files.human_readable --format csv\n</code></pre> <p>Or through the Python API:</p> <pre><code>import os\nfrom onyx import OnyxConfig, OnyxClient, OnyxEnv, OnyxField\n\nconfig = OnyxConfig(\n    domain=os.environ[OnyxEnv.DOMAIN],\n    token=os.environ[OnyxEnv.TOKEN],\n)\n\nwith OnyxClient(config) as client:\n    for summary_data in client.query(\n        \"mscape\",\n        summarise=[\"taxa_files__taxon_id\", \"taxa_files__human_readable\"],\n    ):\n        # Do analysis here\n        print(\"Taxon ID:\", summary_data[\"taxa_files__taxon_id\"])\n        print(\"Taxon name:\", summary_data[\"taxa_files__human_readable\"])\n        print(\"Number of readsets present:\", summary_data[\"count\"])\n</code></pre> <p>Example output for this python script:</p> <pre><code>Taxon ID: 1304\nTaxon name: Streptococcus salivarius\nNumber of readsets present: 22\nTaxon ID: 1305\nTaxon name: Streptococcus sanguinis\nNumber of readsets present: 9\nTaxon ID: 1313\nTaxon name: Streptococcus pneumoniae\nNumber of readsets present: 26\nTaxon ID: 1318\nTaxon name: Streptococcus parasanguinis\nNumber of readsets present: 42\nTaxon ID: 1328\nTaxon name: Streptococcus anginosus\nNumber of readsets present: 4\n...\n</code></pre>"},{"location":"mscape/","title":"mSCAPE Uploader Specification","text":""},{"location":"mscape/#files-to-be-provided","title":"Files to be provided","text":"<p>For paired-end Illumina (<code>illumina</code>) sequencing data, suppliers must provide:</p> <ul> <li>A FASTQ 1 file containing the forward sequencing reads.</li> <li>A FASTQ 2 file containing the reverse sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul> <p>For single-end Illumina (<code>illumina.se</code>) sequencing data, suppliers must provide:</p> <ul> <li>A FASTQ file containing the sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul> <p>For ONT (<code>ont</code>) sequencing data, suppliers must provide:</p> <ul> <li>A FASTQ file containing the sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul> <p>Sequencing data must be dehumanised prior to submission. The ingest pipeline  will reject sequencing data where the number of assigned human reads exceeds the human read rejection threshold.</p>"},{"location":"mscape/#file-naming-convention","title":"File naming convention","text":"<p>The base filenames should be of the form</p> <pre><code>mscape.[run_index].[run_id].[extension]\n</code></pre> <p>where:</p> <ul> <li><code>[run_index]</code> is an identifier that is unique within a sequencing run, e.g. a sequencing barcode identifier, or a 96-well plate co-ordinate.</li> <li><code>[run_id]</code> is the name of the sequencing run as given by the supplier's sequencing instrument (not an internal identifier assigned by the supplier).</li> <li><code>[extension]</code> is the file extension indicating the file type.</li> </ul>"},{"location":"mscape/#file-name-extensions","title":"File name extensions","text":"<p>For paired-end Illumina sequencing data, the extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>1.fastq.gz</code> for the forward FASTQ file.</li> <li><code>2.fastq.gz</code> for the reverse FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul> <p>For single-end Illumina sequencing data, the extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>fastq.gz</code> for the forward FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul> <p>For ONT sequencing data, the extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>fastq.gz</code> for the forward FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul>"},{"location":"mscape/#platforms","title":"Platforms","text":"<ul> <li>For paired-end Illumina sequencing data, the (<code>[platform]</code>) should be <code>illumina</code>.</li> <li>For single-end Illumina sequencing data, the (<code>[platform]</code>) should be <code>illumina.se</code>.</li> <li>For ONT sequencing data, the (<code>[platform]</code>) should be <code>ont</code>.</li> </ul>"},{"location":"mscape/#valid-characters","title":"Valid characters","text":"<p>The <code>[run_index]</code>, <code>[run_id]</code> and <code>[extension]</code> must contain only:</p> <ul> <li>Letters (<code>A-Z</code>, <code>a-z</code>).</li> <li>Numbers (<code>0-9</code>).</li> <li>Hyphens (<code>-</code>).</li> <li>Underscores (<code>_</code>).</li> </ul>"},{"location":"mscape/#buckets","title":"Buckets","text":"<p>Bucket names follow the general convention:</p> <pre><code>mscape-[sequencing_org]-[platform]-[test_flag]\n</code></pre> <p>If you upload your data to an incorrect bucket, it will not be processed or in the worst case may be processed incorrectly, it is your responsibility to ensure that your data is uploaded correctly!</p>"},{"location":"mscape/#metadata-specification","title":"Metadata specification","text":""},{"location":"mscape/#csv-template","title":"CSV Template","text":"<p>A CSV template for uploaders can be downloaded here: mscape-template.csv</p>"},{"location":"mscape/#required-fields","title":"Required fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>biosample_id</code> <code>text</code> The sequencing provider's identifier for a sample. \u2022 Max length: <code>50</code> <code>run_index</code> <code>text</code> The sequencing provider's identifier for the position of a sample on a run. \u2022 Max length: <code>50</code> <code>run_id</code> <code>text</code> Unique identifier assigned to the run by the sequencing instrument. \u2022 Max length: <code>100</code> <code>input_type</code> <code>choice</code> The type of input sequenced. \u2022 Choices: <code>community_standard</code>, <code>negative_control</code>, <code>positive_control</code>, <code>specimen</code>, <code>validation_material</code> <code>sample_source</code> <code>choice</code> The source from which the sample was collected. \u2022 Choices: <code>blood</code>, <code>environment</code>, <code>faecal</code>, <code>lower_respiratory</code>, <code>nose_and_throat</code>, <code>other</code>, <code>plasma</code>, <code>pleural_fluid</code>, <code>stool</code>, <code>tissue</code>, <code>upper_respiratory</code>, <code>urine</code> <code>sample_type</code> <code>choice</code> The type of sampling method used. \u2022 Choices: <code>aspirate</code>, <code>bal</code>, <code>biopsy</code>, <code>other</code>, <code>sputum</code>, <code>swab</code> <code>spike_in</code> <code>choice</code> The type of spike-in used in the run. \u2022 Choices: <code>ERCC-RNA_4456740</code>, <code>bacillus_ms2phage</code>, <code>ms2-phage</code>, <code>none</code>, <code>phix</code>, <code>tobacco_mosaic_virus</code>, <code>zymo_D6320</code>, <code>zymo_D6321</code> <p>At least one of the following fields are required:</p> Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>collection_date</code> <code>date</code> The date the sample was collected. \u2022 Input formats: <code>YYYY-MM</code>, <code>YYYY-MM-DD</code>\u2022 Output format: <code>YYYY-MM-DD</code> <code>received_date</code> <code>date</code> The date the sample was received by the sequencing centre (if collection_date unavailable). \u2022 Input formats: <code>YYYY-MM</code>, <code>YYYY-MM-DD</code>\u2022 Output format: <code>YYYY-MM-DD</code>"},{"location":"mscape/#optional-fields","title":"Optional fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>biosample_source_id</code> <code>text</code> Unique identifier for an individual to permit multiple samples from the same individual to be linked. \u2022 Max length: <code>50</code> <code>specimen_type_details</code> <code>choice</code> Named control or standard for specimens. \u2022 Required when <code>input_type</code> is: <code>specimen</code>\u2022 Choices: <code>asymptomatic</code>, <code>respiratory_infection</code> <code>control_type_details</code> <code>choice</code> Named control or standard for positive and negative controls. \u2022 Required when <code>input_type</code> is: <code>positive_control</code>\u2022 Required when <code>input_type</code> is: <code>negative_control</code>\u2022 Choices: <code>NIBSC_11/242</code>, <code>NIBSC_20/170</code>, <code>bacillus_ms2phage</code>, <code>resp_matrix_mc110</code>, <code>water_extraction_control</code>, <code>zepto_rp2.1</code>, <code>zymo-mc_D6300</code> <code>is_approximate_date</code> <code>bool</code> The date is approximate e.g. the sample is from a public repository and it is unclear whether the date corresponds to collection or publishing. \u2022 Default: <code>False</code> <code>batch_id</code> <code>text</code> Used to identify samples prepared in the same laboratory batch (e.g. extraction, library and/or sequencing). \u2022 Max length: <code>100</code> <code>study_id</code> <code>text</code> Used to identify study or if NHS residual sample. \u2022 Max length: <code>100</code> <code>study_centre_id</code> <code>text</code> Used to identify sequencing centre. \u2022 Max length: <code>100</code> <code>sequence_purpose</code> <code>choice</code> Used to differentiate between clinical or research studies. \u2022 Choices: <code>clinical</code>, <code>research</code> <code>governance_status</code> <code>choice</code> Did the patient consent to their sample being used for research purposes or not. \u2022 Default: <code>no_consent_for_research</code>\u2022 Choices: <code>consented_for_research</code>, <code>no_consent_for_research</code>, <code>open</code> <code>iso_country</code> <code>choice</code> Country that the sample was collected in, using ISO-3166-1 alpha-2 codes (https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2), unless within United Kingdom. If so, use ISO-3166-2:GB (https://en.wikipedia.org/wiki/ISO_3166-2:GB). \u2022 Choices: <code>AD</code>, <code>AE</code>, <code>AF</code>, <code>AG</code>, <code>AI</code>, <code>AL</code>, <code>AM</code>, <code>AO</code>, <code>AQ</code>, <code>AR</code>, <code>AS</code>, <code>AT</code>, <code>AU</code>, <code>AW</code>, <code>AX</code>, <code>AZ</code>, <code>BA</code>, <code>BB</code>, <code>BD</code>, <code>BE</code>, ... <code>iso_region</code> <code>choice</code> Region that the sample was collected in, using the second level subdivision codes of ISO-3166-2:GB (https://www.iso.org/obp/ui/#iso:code:3166:GB). \u2022 Requires: <code>iso_country</code>\u2022 Choices: <code>GB-ABC</code>, <code>GB-ABD</code>, <code>GB-ABE</code>, <code>GB-AGB</code>, <code>GB-AGY</code>, <code>GB-AND</code>, <code>GB-ANN</code>, <code>GB-ANS</code>, <code>GB-BAS</code>, <code>GB-BBD</code>, <code>GB-BCP</code>, <code>GB-BDF</code>, <code>GB-BDG</code>, <code>GB-BEN</code>, <code>GB-BEX</code>, <code>GB-BFS</code>, <code>GB-BGE</code>, <code>GB-BGW</code>, <code>GB-BIR</code>, <code>GB-BKM</code>, ... <code>extraction_enrichment_protocol</code> <code>text</code> Details of nucleic acid extraction and optional enrichment steps. <code>library_protocol</code> <code>text</code> Details of sequencing library construction. <code>sequencing_protocol</code> <code>text</code> Details of sequencing. <code>protocol_arm</code> <code>choice</code> Used to indicate arm for protocols which have separate arms for bacterial and viral nucleic acids. \u2022 Choices: <code>bacterial</code>, <code>viral</code> <code>bioinformatics_protocol</code> <code>text</code> Detail of initial bioinformatics protocol, for example versions of basecalling software and models used, any read quality filtering/trimming employed. <code>dehumanisation_protocol</code> <code>text</code> Details of bioinformatics method used for human read removal. <code>is_public_dataset</code> <code>bool</code> The sample is from a public dataset. Please only set this after it has been made public. \u2022 Default: <code>False</code> <code>public_database_name</code> <code>choice</code> The public repository where the data is. \u2022 Choices: <code>ENA</code>, <code>SRA</code> <code>public_database_accession</code> <code>text</code> The accession for the data in the public database."},{"location":"openmgs-analysis/","title":"openMGS Analysis Specification","text":""},{"location":"openmgs-analysis/#analysis-fields","title":"Analysis fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>published_date</code> <code>date</code> The date the object was published in Onyx. \u2022 Output format: <code>iso-8601</code> <code>site</code> <code>choice</code> The site or sequencing centre providing the data. \u2022 Choices: <code>analysis</code> <code>climb_id</code> <code>text</code> Unique identifier for a project record in Onyx. <code>biosample_id</code> <code>text</code> The sequencing provider's identifier for a sample. <code>biosample_source_id</code> <code>text</code> Unique identifier for an individual to permit multiple samples from the same individual to be linked. <code>run_id</code> <code>text</code> Unique identifier assigned to the run by the sequencing instrument. <code>platform</code> <code>choice</code> The platform used to sequence the data. \u2022 Choices: <code>illumina</code>, <code>illumina.se</code>, <code>ont</code> <code>input_type</code> <code>choice</code> The type of input sequenced. \u2022 Choices: <code>community_standard</code>, <code>negative_control</code>, <code>positive_control</code>, <code>specimen</code>, <code>validation_material</code> <code>specimen_type_details</code> <code>choice</code> Named control or standard for specimens. \u2022 Choices: <code>asymptomatic</code>, <code>gastrointestinal_infection</code>, <code>respiratory_infection</code> <code>control_type_details</code> <code>choice</code> Named control or standard for positive and negative controls. \u2022 Choices: <code>NIBSC_11/242</code>, <code>NIBSC_20/170</code>, <code>bacillus_ms2phage</code>, <code>resp_matrix_mc110</code>, <code>water_extraction_control</code>, <code>zepto_rp2.1</code>, <code>zymo-mc_D6300</code> <code>sample_source</code> <code>choice</code> The source from which the sample was collected. \u2022 Choices: <code>blood</code>, <code>environment</code>, <code>faecal</code>, <code>lower_respiratory</code>, <code>nose_and_throat</code>, <code>other</code>, <code>plasma</code>, <code>pleural_fluid</code>, <code>stool</code>, <code>tissue</code>, <code>upper_respiratory</code>, <code>urine</code> <code>sample_type</code> <code>choice</code> The type of sampling method used. \u2022 Choices: <code>aspirate</code>, <code>bal</code>, <code>biopsy</code>, <code>other</code>, <code>sputum</code>, <code>swab</code> <code>spike_in</code> <code>choice</code> The type of spike-in used in the run. \u2022 Choices: <code>ERCC-RNA_4456740</code>, <code>bacillus_ms2phage</code>, <code>ms2-phage</code>, <code>none</code>, <code>phix</code>, <code>tobacco_mosaic_virus</code>, <code>zymo_D6320</code>, <code>zymo_D6321</code> <code>spike_in_result</code> <code>choice</code> Result assigned by scylla for the provided spike-in. \u2022 Choices: <code>fail</code>, <code>partial</code>, <code>pass</code> <code>collection_date</code> <code>date</code> The date the sample was collected. \u2022 Output format: <code>YYYY-MM-DD</code> <code>received_date</code> <code>date</code> The date the sample was received by the sequencing centre (if collection_date unavailable). \u2022 Output format: <code>YYYY-MM-DD</code> <code>is_approximate_date</code> <code>bool</code> The date is approximate e.g. the sample is from a public repository and it is unclear whether the date corresponds to collection or publishing. <code>batch_id</code> <code>text</code> Used to identify samples prepared in the same laboratory batch (e.g. extraction, library and/or sequencing). <code>study_id</code> <code>text</code> Used to identify study or if NHS residual sample. <code>study_centre_id</code> <code>text</code> Used to identify sequencing centre. <code>sequence_purpose</code> <code>choice</code> Used to differentiate between clinical or research studies. \u2022 Choices: <code>clinical</code>, <code>research</code> <code>governance_status</code> <code>choice</code> Did the patient consent to their sample being used for research purposes or not. \u2022 Choices: <code>consented_for_research</code>, <code>no_consent_for_research</code>, <code>open</code> <code>iso_country</code> <code>choice</code> Country that the sample was collected in, using ISO-3166-1 alpha-2 codes (https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2), unless within United Kingdom. If so, use ISO-3166-2:GB (https://en.wikipedia.org/wiki/ISO_3166-2:GB). \u2022 Choices: <code>AD</code>, <code>AE</code>, <code>AF</code>, <code>AG</code>, <code>AI</code>, <code>AL</code>, <code>AM</code>, <code>AO</code>, <code>AQ</code>, <code>AR</code>, <code>AS</code>, <code>AT</code>, <code>AU</code>, <code>AW</code>, <code>AX</code>, <code>AZ</code>, <code>BA</code>, <code>BB</code>, <code>BD</code>, <code>BE</code>, ... <code>iso_region</code> <code>choice</code> Region that the sample was collected in, using the second level subdivision codes of ISO-3166-2:GB (https://www.iso.org/obp/ui/#iso:code:3166:GB). \u2022 Choices: <code>GB-ABC</code>, <code>GB-ABD</code>, <code>GB-ABE</code>, <code>GB-AGB</code>, <code>GB-AGY</code>, <code>GB-AND</code>, <code>GB-ANN</code>, <code>GB-ANS</code>, <code>GB-BAS</code>, <code>GB-BBD</code>, <code>GB-BCP</code>, <code>GB-BDF</code>, <code>GB-BDG</code>, <code>GB-BEN</code>, <code>GB-BEX</code>, <code>GB-BFS</code>, <code>GB-BGE</code>, <code>GB-BGW</code>, <code>GB-BIR</code>, <code>GB-BKM</code>, ... <code>extraction_enrichment_protocol</code> <code>text</code> Details of nucleic acid extraction and optional enrichment steps. <code>library_protocol</code> <code>text</code> Details of sequencing library construction. <code>sequencing_protocol</code> <code>text</code> Details of sequencing. <code>protocol_arm</code> <code>choice</code> Used to indicate arm for protocols which have separate arms for bacterial and viral nucleic acids. \u2022 Choices: <code>bacterial</code>, <code>viral</code> <code>bioinformatics_protocol</code> <code>text</code> Detail of initial bioinformatics protocol, for example versions of basecalling software and models used, any read quality filtering/trimming employed. <code>dehumanisation_protocol</code> <code>text</code> Details of bioinformatics method used for human read removal. <code>is_public_dataset</code> <code>bool</code> The sample is from a public dataset. Please only set this after it has been made public. <code>public_database_name</code> <code>choice</code> The public repository where the data is. \u2022 Choices: <code>ENA</code>, <code>SRA</code> <code>public_database_accession</code> <code>text</code> The accession for the data in the public database. <code>ingest_report</code> <code>text</code> HTML report summarising the read profile and taxa identified. <code>taxon_reports</code> <code>text</code> Folder of all classification output files. <code>human_filtered_reads_1</code> <code>text</code> Compressed FASTQ of input reads that have been filtered for human reads. <code>human_filtered_reads_2</code> <code>text</code> Compressed FASTQ of input reads that have been filtered for human reads. <code>unclassified_reads_1</code> <code>text</code> Compressed FASTQ of input reads which could not be classified. <code>unclassified_reads_2</code> <code>text</code> Compressed FASTQ of input reads which could not be classified. <code>viral_reads_1</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral. <code>viral_reads_2</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral. <code>viral_and_unclassified_reads_1</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral or were unclassified. <code>viral_and_unclassified_reads_2</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral or were unclassified. <code>total_bases</code> <code>integer</code> Total number of bases in the input FASTQ file(s), before any filtering. <code>classifier</code> <code>choice</code> The classifier used. \u2022 Choices: <code>Kraken2</code> <code>classifier_version</code> <code>text</code> Version of the classifier used. <code>classifier_db</code> <code>choice</code> Database used for read classification. \u2022 Choices: <code>PlusPF</code> <code>classifier_db_date</code> <code>date</code> Date classifier database was produced. \u2022 Output format: <code>YYYY-MM-DD</code> <code>ncbi_taxonomy_date</code> <code>date</code> Date that the NCBI taxonomy dump was produced. \u2022 Output format: <code>YYYY-MM-DD</code> <code>scylla_version</code> <code>text</code> Version of the scylla pipeline used. <code>chimera_bam</code> <code>text</code> BAM file of the human filtered read fraction aligned to the zeus database. <code>is_chimera_published</code> <code>bool</code> Whether chimera has been run on this record or not. <code>alignment_db_version</code> <code>text</code> Version of the Zeus database used. <code>sylph_db_version</code> <code>text</code> Sylph database version utilised to produce Sylph classifications. <code>taxa_files</code> <code>relation</code> Table of all species level taxa extracted by the Scylla ingest pipeline. <code>taxa_files.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>taxa_files.human_readable</code> <code>text</code> A human readable name for the taxa. <code>taxa_files.n_reads</code> <code>integer</code> The number of reads extracted for the taxa. <code>taxa_files.total_bases</code> <code>integer</code> Total number of bases extracted for the taxa. <code>taxa_files.avg_quality</code> <code>decimal</code> The mean quality of reads extracted for the taxa. <code>taxa_files.mean_len</code> <code>decimal</code> The mean length of reads extracted for the taxa. <code>taxa_files.rank</code> <code>choice</code> The rank of the taxa. \u2022 Choices: <code>C</code>, <code>D</code>, <code>F</code>, <code>G</code>, <code>K</code>, <code>O</code>, <code>P</code>, <code>R</code>, <code>S</code>, <code>U</code> <code>taxa_files.fastq_1</code> <code>text</code> Compressed FASTQ of extracted reads for the taxa. <code>taxa_files.fastq_2</code> <code>text</code> Compressed FASTQ of extracted reads for the taxa. <code>classifier_calls</code> <code>relation</code> Table summarising the NCBI taxonomy ids, counts and ranks of all taxa found by the classifier during the Scylla ingest pipeline. <code>classifier_calls.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>classifier_calls.human_readable</code> <code>text</code> A human readable name for the taxa. <code>classifier_calls.percentage</code> <code>decimal</code> The percentage of the (dehumanised) sample that the taxa represents. <code>classifier_calls.count_descendants</code> <code>integer</code> The number of reads mapping to this taxa and all descendant taxa. <code>classifier_calls.count_direct</code> <code>integer</code> The number of reads mapping directly to the taxa. <code>classifier_calls.rank</code> <code>choice</code> The rank of the taxa. \u2022 Choices: <code>C</code>, <code>D</code>, <code>F</code>, <code>G</code>, <code>K</code>, <code>O</code>, <code>P</code>, <code>R</code>, <code>S</code>, <code>U</code> <code>classifier_calls.raw_rank</code> <code>text</code> The rank of the taxa including an intermediate grading. <code>classifier_calls.is_spike_in</code> <code>bool</code> The taxa is a spike-in. <code>spike_in_info</code> <code>relation</code> Table containing results found for the provided spike-in. <code>spike_in_info.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>spike_in_info.human_readable</code> <code>text</code> A human readable name for the taxa. <code>spike_in_info.reference_header</code> <code>text</code> Reference header for the individual sequence within the provided spike-in. <code>spike_in_info.mapped_count</code> <code>integer</code> Number of reads which aligned to a reference sequence for the provided spike-in. <code>alignment_results</code> <code>relation</code> Table containing alignment results from the viral alignment stage of the CLIMB-TRE/chimera pipeline. <code>alignment_results.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>alignment_results.human_readable</code> <code>text</code> Human readable scientific name for the taxa. <code>alignment_results.unique_accession</code> <code>text</code> Unique reference identifier in the alignment database (everything prior to the first whitespace in the FASTA header). <code>alignment_results.accession_description</code> <code>text</code> The comment for the reference sequence within the alignment database. <code>alignment_results.sequence_length</code> <code>integer</code> Length of the reference sequence in the alignment database. <code>alignment_results.evenness_value</code> <code>integer</code> A percentage indicating how evenly read depths are distributed throughout the reference, with 0 being completely uneven, and 100 being perfectly even. Taken from https://academic.oup.com/nar/article/38/10/e116/2902812, under the \u201cCalculation of evenness score\u201d section, and calculated here: https://github.com/CLIMB-TRE/chimera/blob/dca3cacb949dabc902d0a12e5d11d36c6ac555fd/bin/generate_alignment_report.py#L102. <code>alignment_results.mean_depth</code> <code>integer</code> Mean of all depth values across the alignment reference. <code>alignment_results.coverage_1x</code> <code>integer</code> Percentage of the reference sequence covered with a depth of at least 1x. <code>alignment_results.coverage_10x</code> <code>integer</code> Percentage of the reference covered with a depth of at least 10x. <code>alignment_results.mapped_reads</code> <code>integer</code> Total number of reads mapped to the alignment reference. <code>alignment_results.uniquely_mapped_reads</code> <code>integer</code> Total number of reads which uniquely map to each reference sequence, calculated for each reference sequence here: https://github.com/CLIMB-TRE/chimera/blob/bca6fe6fe293f8e56d9e70627a846dda6f3d886a/bin/generate_alignment_report.py#L59-L82. <code>alignment_results.mapped_bases</code> <code>integer</code> Approximation for the total number of bases mapped to the alignment reference, calculated from the length of the reference sequence multiplied by the mean depth of alignments to that reference. <code>alignment_results.mean_read_identity</code> <code>decimal</code> Mean of read identities across all alignments. Can be considered an approximation for identity of the source genome with the reference sequence. Calculated for each read here: https://github.com/CLIMB-TRE/chimera/blob/dca3cacb949dabc902d0a12e5d11d36c6ac555fd/bin/generate_alignment_report.py#L58 <code>alignment_results.read_duplication_rate</code> <code>decimal</code> What proportion of the reads start and end in the same alignment reference position as at least one other read within the alignment. Calculated here: https://github.com/CLIMB-TRE/chimera/blob/dca3cacb949dabc902d0a12e5d11d36c6ac555fd/bin/generate_alignment_report.py#L76-L83 <code>alignment_results.forward_proportion</code> <code>decimal</code> Proportion of reads which aligned to the forward strand. Between 0 and 1, with 0 indicating all reads aligned to the reverse strand, 1 the opposite. True hits should be close to 0.5 for this value for any reasonable mean depth. <code>alignment_results.mean_alignment_length</code> <code>decimal</code> Mean length of all alignments to the reference - different to mean read length aligned to the reference, since it only considers the aligned section of the reads. <code>sylph_results</code> <code>relation</code> Table containing sylph results from the Sylph classification stage of the CLIMB-TRE/chimera pipeline. <code>sylph_results.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>sylph_results.human_readable</code> <code>text</code> Human readable scientific name for the taxa. <code>sylph_results.gtdb_taxon_string</code> <code>text</code> Description of the taxonomic placement of the source contig within the Sylph database using GTDBs taxon string format. <code>sylph_results.gtdb_assembly_id</code> <code>text</code> Assembly ID (often genbank accession) for the contig within the sylph database, taken from GTDB. <code>sylph_results.gtdb_contig_header</code> <code>text</code> From the origin FASTA record header as it appears in GTDB. Identical to 'Contig_name' field in sylph profile output. <code>sylph_results.taxonomic_abundance</code> <code>decimal</code> Normalized taxonomic abundance as a percentage. Identical to 'Taxonomic_abundance' in sylph profile output. <code>sylph_results.sequence_abundance</code> <code>decimal</code> Normalized sequence abundance as a percentage. Identical to 'Sequence_abundance' in sylph profile output. <code>sylph_results.adjusted_ani</code> <code>decimal</code> If coverage adjustment is possible (cov is &lt; 3x cov): returns coverage-adjusted ANI (Average Nucleotide Identity). If coverage is too low/high: returns naive_ani. Identical to 'Adjusted_ANI' in sylph profile output. <code>sylph_results.ani_confidence_interval</code> <code>text</code> [5%,95%] confidence intervals. If coverage adjustment is possible: float-float e.g. 98.52-99.55. If coverage is too low/high: NA-NA is given. Identical to 'ANI_5-95_percentile' field in sylph profile output. <code>sylph_results.effective_coverage</code> <code>decimal</code> Estimated '\u03bbeff' value, true value is not calculated, this is estimated based on kmers. More information is available in the sylph paper: https://www.nature.com/articles/s41587-024-02412-y. If coverage adjustment is possible, lambda estimate is given. Identical to 'Eff_cov' field in sylph profile output. <code>sylph_results.effective_coverage_confidence_interval</code> <code>text</code> [5%, 95%] confidence intervals for lambda. Same format rules as 'ani_confidence_interval'. Identical to 'Lambda_5-95_percentile' field in sylph profile output. <code>sylph_results.median_kmer_cov</code> <code>integer</code> Median k-mer multiplicity for k-mers with &gt;= 1 multiplicity. Identical to 'Median_cov' field in sylph profile output. <code>sylph_results.mean_kmer_cov</code> <code>decimal</code> Mean k-mer multiplicity for k-mers with &gt;= 1 multiplicity. Identical to 'Mean_cov_geq1' field in sylph profile output. <code>sylph_results.containment_index</code> <code>text</code> int/int showing the containment index (number of k-mers found in sample divided by total k-mers), e.g. 959/1053. Identical to 'Containment_ind' field in sylph profile output. <code>sylph_results.naive_ani</code> <code>decimal</code> Containment ANI without coverage adjustment. Identical to 'Naive_ANI' field in sylph profile output. <code>sylph_results.kmers_reassigned</code> <code>integer</code> The number of k-mers reassigned away from the genome. Identical to 'Kmers_reassigned' field in sylph profile output."},{"location":"openmgs/","title":"openMGS Uploader Specification","text":""},{"location":"openmgs/#files-to-be-provided","title":"Files to be provided","text":"<p>For paired-end Illumina sequencing data, suppliers must provide:</p> <ul> <li>A FASTQ 1 file containing the forward sequencing reads.</li> <li>A FASTQ 2 file containing the reverse sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul> <p>For single-end Illumina sequencing data, suppliers must provide:</p> <ul> <li>A FASTQ file containing the sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul> <p>For ONT sequencing data, suppliers must provide:</p> <ul> <li>A FASTQ file containing the sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul> <p>Sequencing data must be dehumanised prior to submission. The ingest pipeline will reject sequencing data where the number of assigned human reads exceeds the human read rejection threshold.</p>"},{"location":"openmgs/#file-naming-convention","title":"File naming convention","text":"<p>The base filenames should be of the form</p> <pre><code>openmgs.[run_index].[run_id].[extension]\n</code></pre> <p>where:</p> <ul> <li><code>[run_index]</code> is an identifier that is unique within a sequencing run, e.g. a sequencing barcode identifier, or a 96-well plate co-ordinate.</li> <li><code>[run_id]</code> is the name of the sequencing run as given by the supplier's sequencing instrument (not an internal identifier assigned by the supplier).</li> <li><code>[extension]</code> is the file extension indicating the file type.</li> </ul>"},{"location":"openmgs/#file-name-extensions","title":"File name extensions","text":"<p>For paired-end Illumina sequencing data, the extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>1.fastq.gz</code> for the forward FASTQ file.</li> <li><code>2.fastq.gz</code> for the reverse FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul> <p>For single-end Illumina sequencing data, the extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>fastq.gz</code> for the forward FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul> <p>For ONT sequencing data, the extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>fastq.gz</code> for the forward FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul>"},{"location":"openmgs/#valid-characters","title":"Valid characters","text":"<p>The <code>[run_index]</code>, <code>[run_id]</code> and <code>[extension]</code> must contain only:</p> <ul> <li>Letters (<code>A-Z</code>, <code>a-z</code>).</li> <li>Numbers (<code>0-9</code>).</li> <li>Hyphens (<code>-</code>).</li> <li>Underscores (<code>_</code>).</li> </ul>"},{"location":"openmgs/#buckets","title":"Buckets","text":"<p>Bucket names follow the general convention:</p> <pre><code>openmgs-[sequencing_org]-[platform]-[test_flag]\n</code></pre>"},{"location":"openmgs/#metadata-specification","title":"Metadata specification","text":""},{"location":"openmgs/#csv-template","title":"CSV Template","text":"<p>A CSV template for uploaders can be downloaded here: openmgs-template.csv</p>"},{"location":"openmgs/#required-fields","title":"Required fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>biosample_id</code> <code>text</code> The sequencing provider's identifier for a sample. \u2022 Max length: <code>50</code> <code>run_index</code> <code>text</code> The sequencing provider's identifier for the position of a sample on a run. \u2022 Max length: <code>50</code> <code>run_id</code> <code>text</code> Unique identifier assigned to the run by the sequencing instrument. \u2022 Max length: <code>100</code> <code>input_type</code> <code>choice</code> The type of input sequenced. \u2022 Choices: <code>community_standard</code>, <code>negative_control</code>, <code>positive_control</code>, <code>specimen</code>, <code>validation_material</code> <code>sample_source</code> <code>choice</code> The source from which the sample was collected. \u2022 Choices: <code>blood</code>, <code>environment</code>, <code>faecal</code>, <code>lower_respiratory</code>, <code>nose_and_throat</code>, <code>other</code>, <code>plasma</code>, <code>pleural_fluid</code>, <code>stool</code>, <code>tissue</code>, <code>upper_respiratory</code>, <code>urine</code> <code>sample_type</code> <code>choice</code> The type of sampling method used. \u2022 Choices: <code>aspirate</code>, <code>bal</code>, <code>biopsy</code>, <code>other</code>, <code>sputum</code>, <code>swab</code> <code>spike_in</code> <code>choice</code> The type of spike-in used in the run. \u2022 Choices: <code>ERCC-RNA_4456740</code>, <code>bacillus_ms2phage</code>, <code>ms2-phage</code>, <code>none</code>, <code>phix</code>, <code>tobacco_mosaic_virus</code>, <code>zymo_D6320</code>, <code>zymo_D6321</code> <p>At least one of the following fields are required:</p> Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>collection_date</code> <code>date</code> The date the sample was collected. \u2022 Input formats: <code>YYYY-MM</code>, <code>YYYY-MM-DD</code>\u2022 Output format: <code>YYYY-MM-DD</code> <code>received_date</code> <code>date</code> The date the sample was received by the sequencing centre (if collection_date unavailable). \u2022 Input formats: <code>YYYY-MM</code>, <code>YYYY-MM-DD</code>\u2022 Output format: <code>YYYY-MM-DD</code>"},{"location":"openmgs/#optional-fields","title":"Optional fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>biosample_source_id</code> <code>text</code> Unique identifier for an individual to permit multiple samples from the same individual to be linked. \u2022 Max length: <code>50</code> <code>specimen_type_details</code> <code>choice</code> Named control or standard for specimens. \u2022 Required when <code>input_type</code> is: <code>specimen</code>\u2022 Choices: <code>asymptomatic</code>, <code>gastrointestinal_infection</code>, <code>respiratory_infection</code> <code>control_type_details</code> <code>choice</code> Named control or standard for positive and negative controls. \u2022 Required when <code>input_type</code> is: <code>positive_control</code>\u2022 Required when <code>input_type</code> is: <code>negative_control</code>\u2022 Choices: <code>NIBSC_11/242</code>, <code>NIBSC_20/170</code>, <code>bacillus_ms2phage</code>, <code>resp_matrix_mc110</code>, <code>water_extraction_control</code>, <code>zepto_rp2.1</code>, <code>zymo-mc_D6300</code> <code>is_approximate_date</code> <code>bool</code> The date is approximate e.g. the sample is from a public repository and it is unclear whether the date corresponds to collection or publishing. \u2022 Default: <code>False</code> <code>batch_id</code> <code>text</code> Used to identify samples prepared in the same laboratory batch (e.g. extraction, library and/or sequencing). \u2022 Max length: <code>100</code> <code>study_id</code> <code>text</code> Used to identify study or if NHS residual sample. \u2022 Max length: <code>100</code> <code>study_centre_id</code> <code>text</code> Used to identify sequencing centre. \u2022 Max length: <code>100</code> <code>sequence_purpose</code> <code>choice</code> Used to differentiate between clinical or research studies. \u2022 Choices: <code>clinical</code>, <code>research</code> <code>governance_status</code> <code>choice</code> Did the patient consent to their sample being used for research purposes or not. \u2022 Default: <code>no_consent_for_research</code>\u2022 Choices: <code>consented_for_research</code>, <code>no_consent_for_research</code>, <code>open</code> <code>iso_country</code> <code>choice</code> Country that the sample was collected in, using ISO-3166-1 alpha-2 codes (https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2), unless within United Kingdom. If so, use ISO-3166-2:GB (https://en.wikipedia.org/wiki/ISO_3166-2:GB). \u2022 Choices: <code>AD</code>, <code>AE</code>, <code>AF</code>, <code>AG</code>, <code>AI</code>, <code>AL</code>, <code>AM</code>, <code>AO</code>, <code>AQ</code>, <code>AR</code>, <code>AS</code>, <code>AT</code>, <code>AU</code>, <code>AW</code>, <code>AX</code>, <code>AZ</code>, <code>BA</code>, <code>BB</code>, <code>BD</code>, <code>BE</code>, ... <code>iso_region</code> <code>choice</code> Region that the sample was collected in, using the second level subdivision codes of ISO-3166-2:GB (https://www.iso.org/obp/ui/#iso:code:3166:GB). \u2022 Requires: <code>iso_country</code>\u2022 Choices: <code>GB-ABC</code>, <code>GB-ABD</code>, <code>GB-ABE</code>, <code>GB-AGB</code>, <code>GB-AGY</code>, <code>GB-AND</code>, <code>GB-ANN</code>, <code>GB-ANS</code>, <code>GB-BAS</code>, <code>GB-BBD</code>, <code>GB-BCP</code>, <code>GB-BDF</code>, <code>GB-BDG</code>, <code>GB-BEN</code>, <code>GB-BEX</code>, <code>GB-BFS</code>, <code>GB-BGE</code>, <code>GB-BGW</code>, <code>GB-BIR</code>, <code>GB-BKM</code>, ... <code>extraction_enrichment_protocol</code> <code>text</code> Details of nucleic acid extraction and optional enrichment steps. <code>library_protocol</code> <code>text</code> Details of sequencing library construction. <code>sequencing_protocol</code> <code>text</code> Details of sequencing. <code>protocol_arm</code> <code>choice</code> Used to indicate arm for protocols which have separate arms for bacterial and viral nucleic acids. \u2022 Choices: <code>bacterial</code>, <code>viral</code> <code>bioinformatics_protocol</code> <code>text</code> Detail of initial bioinformatics protocol, for example versions of basecalling software and models used, any read quality filtering/trimming employed. <code>dehumanisation_protocol</code> <code>text</code> Details of bioinformatics method used for human read removal. <code>is_public_dataset</code> <code>bool</code> The sample is from a public dataset. Please only set this after it has been made public. \u2022 Default: <code>False</code> <code>public_database_name</code> <code>choice</code> The public repository where the data is. \u2022 Choices: <code>ENA</code>, <code>SRA</code> <code>public_database_accession</code> <code>text</code> The accession for the data in the public database."},{"location":"pathsafe-analysis/","title":"PATH-SAFE Analysis Specification","text":""},{"location":"pathsafe-analysis/#analysis-fields","title":"Analysis fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>published_date</code> <code>date</code> The date the object was published in Onyx. \u2022 Output format: <code>iso-8601</code> <code>site</code> <code>choice</code> Laboratory, organisation or agency the sample has been submitted by. \u2022 Choices: <code>APHA</code>, <code>CGPS</code>, <code>FSA</code>, <code>FSS</code>, <code>PHS</code>, <code>SSSCDRL</code>, <code>UKHSA</code> <code>climb_id</code> <code>text</code> Unique identifier for a project record in Onyx. <code>biosample_id</code> <code>text</code> The sequencing providers identifier for a sample. <code>biosample_source_id</code> <code>text</code> Unique identifier for an individual to permit multiple samples from the same individual to be linked. <code>run_id</code> <code>text</code> The unique identifier assigned to the run by the sequencing instrument. <code>platform</code> <code>choice</code> The platform used to sequence the data. \u2022 Choices: <code>illumina</code> <code>submitted_species</code> <code>choice</code> The NCBI taxonomy id provided for the sample. \u2022 Choices: <code>1639</code>, <code>28901</code>, <code>562</code> <code>sample_accession</code> <code>text</code> Sample accession number if sequence is publically available in SRA. <code>enterobase_barcode</code> <code>text</code> Sample barcode if sequence is publically available in EnteroBase. <code>collection_date</code> <code>date</code> Date of sample collection. \u2022 Output format: <code>YYYY-MM</code> <code>receipt_date</code> <code>date</code> Date of receipt of the sample. \u2022 Output format: <code>YYYY-MM</code> <code>month</code> <code>integer</code> Month of sample collected if available or month of receipt otherwise. <code>year</code> <code>integer</code> Year of sample collected if available or year of sample receipt otherwise. <code>sequence_org</code> <code>choice</code> Laboratory, organisation or agency the sample has been sequenced by. \u2022 Choices: <code>APHA</code>, <code>FSA</code>, <code>FSS</code>, <code>OTHER</code>, <code>PHS</code>, <code>PHW</code>, <code>SEPA</code>, <code>SSSCDRL</code>, <code>UKHSA</code> <code>sequence_org_other</code> <code>text</code> Additional laboratory, organisation or agency the sample has been sequenced by. <code>data_steward</code> <code>choice</code> Laboratory, organisation or agency that hold the data for the sample. \u2022 Choices: <code>APHA</code>, <code>FSA</code>, <code>FSS</code>, <code>OTHER</code>, <code>PHS</code>, <code>PHW</code>, <code>SEPA</code>, <code>SSSCDRL</code>, <code>UKHSA</code> <code>data_steward_other</code> <code>text</code> Additional laboratory, organisation or agency that hold the data for the sample. <code>source_type</code> <code>choice</code> Source of the sample. \u2022 Choices: <code>animal</code>, <code>animal_associated_environment</code>, <code>environment</code>, <code>food</code>, <code>food_associated_environment</code>, <code>human</code>, <code>human_associated_environment</code>, <code>missing</code>, <code>not_applicable</code>, <code>not_collected</code>, <code>not_provided</code>, <code>other</code>, <code>other_environment</code>, <code>restricted_access</code> <code>country</code> <code>choice</code> The country that the sample was collected in, using ISO-3166-1 alpha-2 codes (https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes), unless within United Kingdom. If so, use ISO-3166-2:GB (https://en.wikipedia.org/wiki/ISO_3166-2:GB). \u2022 Choices: <code>GB</code>, <code>GB-ENG</code>, <code>GB-NIR</code>, <code>GB-SCT</code>, <code>GB-WLS</code> <code>county</code> <code>choice</code> County that the sample was collected in, using the second level subdivision codes of ISO-3166-2:GB (https://www.iso.org/obp/ui/#iso:code:3166:GB). \u2022 Choices: <code>GB-ABC</code>, <code>GB-ABD</code>, <code>GB-ABE</code>, <code>GB-AGB</code>, <code>GB-AGY</code>, <code>GB-AND</code>, <code>GB-ANN</code>, <code>GB-ANS</code>, <code>GB-BAS</code>, <code>GB-BBD</code>, <code>GB-BCP</code>, <code>GB-BDF</code>, <code>GB-BDG</code>, <code>GB-BEN</code>, <code>GB-BEX</code>, <code>GB-BFS</code>, <code>GB-BGE</code>, <code>GB-BGW</code>, <code>GB-BIR</code>, <code>GB-BKM</code>, ... <code>sample_purpose</code> <code>choice</code> The purpose of the sample collection. \u2022 Choices: <code>active_surveillance</code>, <code>not_applicable</code>, <code>not_collected</code>, <code>not_provided</code>, <code>other</code>, <code>outbreak_initiated_surveillance</code>, <code>outbreak_investigation</code>, <code>population_based_surveillance</code>, <code>research</code>, <code>restricted_access</code>, <code>routine_diagnostics</code>, <code>routine_surveillance</code> <code>sample_purpose_other</code> <code>text</code> Additional purpose of the sample collection. <code>sequencing_kit</code> <code>text</code> The sequencing kit used. <code>library_kit</code> <code>text</code> The library kit used to prep the sample. <code>is_multiplexed</code> <code>bool</code> Whether the sample was multiplexed. <code>type_of_sample</code> <code>choice</code> Type of sample used to produce the sequence. \u2022 Choices: <code>genomic</code> <code>assembly</code> <code>text</code> Assembly FASTA file. <code>pathogenwatch_uuid</code> <code>text</code> UUID from Pathogenwatch."},{"location":"pathsafe/","title":"PATH-SAFE Uploader Specification","text":""},{"location":"pathsafe/#files-to-be-provided","title":"Files to be provided","text":"<ul> <li>A FASTQ 1 file containing the forward sequencing reads.</li> <li>A FASTQ 2 file containing the reverse sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul>"},{"location":"pathsafe/#file-naming-convention","title":"File naming convention","text":"<p>The base filenames should be of the form</p> <pre><code>pathsafe.[run_index].[run_id].[extension]\n</code></pre> <p>where:</p> <ul> <li><code>[run_index]</code> is an identifier that is unique within a sequencing run, e.g. a sequencing barcode identifier, or a 96-well plate co-ordinate.</li> <li><code>[run_id]</code> is the name of the sequencing run as given by the supplier's sequencing instrument (not an internal identifier assigned by the supplier).</li> <li><code>[extension]</code> is the file extension indicating the file type.</li> </ul>"},{"location":"pathsafe/#file-name-extensions","title":"File name extensions","text":"<p>The extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>1.fastq.gz</code> for the forward FASTQ file.</li> <li><code>2.fastq.gz</code> for the reverse FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul>"},{"location":"pathsafe/#valid-characters","title":"Valid characters","text":"<p>The <code>[run_index]</code>, <code>[run_id]</code> and <code>[extension]</code> must contain only:</p> <ul> <li>Letters (<code>A-Z</code>, <code>a-z</code>).</li> <li>Numbers (<code>0-9</code>).</li> <li>Hyphens (<code>-</code>).</li> <li>Underscores (<code>_</code>).</li> </ul>"},{"location":"pathsafe/#metadata-specification","title":"Metadata specification","text":""},{"location":"pathsafe/#csv-template","title":"CSV Template","text":"<p>A CSV template for uploaders can be downloaded here: pathsafe-template.csv</p>"},{"location":"pathsafe/#required-fields","title":"Required fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>biosample_id</code> <code>text</code> The sequencing providers identifier for a sample. \u2022 Max length: <code>50</code> <code>run_index</code> <code>text</code> The sequencing provider's identifier for the position of a sample on a run. \u2022 Max length: <code>50</code> <code>run_id</code> <code>text</code> The unique identifier assigned to the run by the sequencing instrument. \u2022 Max length: <code>100</code> <code>submitted_species</code> <code>choice</code> The NCBI taxonomy id provided for the sample. \u2022 Choices: <code>1639</code>, <code>28901</code>, <code>562</code> <code>year</code> <code>integer</code> Year of sample collected if available or year of sample receipt otherwise. \u2022 Min value: <code>2000</code> <code>data_steward</code> <code>choice</code> Laboratory, organisation or agency that hold the data for the sample. \u2022 Choices: <code>APHA</code>, <code>FSA</code>, <code>FSS</code>, <code>OTHER</code>, <code>PHS</code>, <code>PHW</code>, <code>SEPA</code>, <code>SSSCDRL</code>, <code>UKHSA</code> <code>source_type</code> <code>choice</code> Source of the sample. \u2022 Choices: <code>animal</code>, <code>animal_associated_environment</code>, <code>environment</code>, <code>food</code>, <code>food_associated_environment</code>, <code>human</code>, <code>human_associated_environment</code>, <code>missing</code>, <code>not_applicable</code>, <code>not_collected</code>, <code>not_provided</code>, <code>other</code>, <code>other_environment</code>, <code>restricted_access</code> <code>country</code> <code>choice</code> The country that the sample was collected in, using ISO-3166-1 alpha-2 codes (https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes), unless within United Kingdom. If so, use ISO-3166-2:GB (https://en.wikipedia.org/wiki/ISO_3166-2:GB). \u2022 Choices: <code>GB</code>, <code>GB-ENG</code>, <code>GB-NIR</code>, <code>GB-SCT</code>, <code>GB-WLS</code> <code>sample_purpose</code> <code>choice</code> The purpose of the sample collection. \u2022 Choices: <code>active_surveillance</code>, <code>not_applicable</code>, <code>not_collected</code>, <code>not_provided</code>, <code>other</code>, <code>outbreak_initiated_surveillance</code>, <code>outbreak_investigation</code>, <code>population_based_surveillance</code>, <code>research</code>, <code>restricted_access</code>, <code>routine_diagnostics</code>, <code>routine_surveillance</code>"},{"location":"pathsafe/#optional-fields","title":"Optional fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>biosample_source_id</code> <code>text</code> Unique identifier for an individual to permit multiple samples from the same individual to be linked. \u2022 Max length: <code>50</code> <code>sample_accession</code> <code>text</code> Sample accession number if sequence is publically available in SRA. <code>enterobase_barcode</code> <code>text</code> Sample barcode if sequence is publically available in EnteroBase. <code>collection_date</code> <code>date</code> Date of sample collection. \u2022 Input formats: <code>YYYY-MM</code>\u2022 Output format: <code>YYYY-MM</code> <code>receipt_date</code> <code>date</code> Date of receipt of the sample. \u2022 Input formats: <code>YYYY-MM</code>\u2022 Output format: <code>YYYY-MM</code> <code>month</code> <code>integer</code> Month of sample collected if available or month of receipt otherwise. \u2022 Min value: <code>1</code>\u2022 Max value: <code>12</code> <code>sequence_org</code> <code>choice</code> Laboratory, organisation or agency the sample has been sequenced by. \u2022 Choices: <code>APHA</code>, <code>FSA</code>, <code>FSS</code>, <code>OTHER</code>, <code>PHS</code>, <code>PHW</code>, <code>SEPA</code>, <code>SSSCDRL</code>, <code>UKHSA</code> <code>sequence_org_other</code> <code>text</code> Additional laboratory, organisation or agency the sample has been sequenced by. \u2022 Requires: <code>sequence_org</code>\u2022 Required when <code>sequence_org</code> is: <code>OTHER</code> <code>data_steward_other</code> <code>text</code> Additional laboratory, organisation or agency that hold the data for the sample. \u2022 Requires: <code>data_steward</code>\u2022 Required when <code>data_steward</code> is: <code>OTHER</code> <code>county</code> <code>choice</code> County that the sample was collected in, using the second level subdivision codes of ISO-3166-2:GB (https://www.iso.org/obp/ui/#iso:code:3166:GB). \u2022 Requires: <code>country</code>\u2022 Choices: <code>GB-ABC</code>, <code>GB-ABD</code>, <code>GB-ABE</code>, <code>GB-AGB</code>, <code>GB-AGY</code>, <code>GB-AND</code>, <code>GB-ANN</code>, <code>GB-ANS</code>, <code>GB-BAS</code>, <code>GB-BBD</code>, <code>GB-BCP</code>, <code>GB-BDF</code>, <code>GB-BDG</code>, <code>GB-BEN</code>, <code>GB-BEX</code>, <code>GB-BFS</code>, <code>GB-BGE</code>, <code>GB-BGW</code>, <code>GB-BIR</code>, <code>GB-BKM</code>, ... <code>sample_purpose_other</code> <code>text</code> Additional purpose of the sample collection. \u2022 Requires: <code>sample_purpose</code>\u2022 Required when <code>sample_purpose</code> is: <code>other</code> <code>sequencing_kit</code> <code>text</code> The sequencing kit used. <code>library_kit</code> <code>text</code> The library kit used to prep the sample. <code>is_multiplexed</code> <code>bool</code> Whether the sample was multiplexed. <code>type_of_sample</code> <code>choice</code> Type of sample used to produce the sequence. \u2022 Default: <code>genomic</code>\u2022 Choices: <code>genomic</code>"},{"location":"results/","title":"Checking Results After Submitting Data","text":""},{"location":"results/#bryn-gui","title":"Bryn GUI","text":"<p>The Bryn GUI is the simplest way to check on the status of submitted data for most users. To do so, simply log in to Bryn. </p> <p>Once there navigate to the \"S3 Buckets\" menu on the left which should look like this: </p> <p>Then select the results bucket by clicking on it, the name of the results bucket will differ based on the CLIMB-TRE project and which site you belong to but the layout will be: <code>{project}-{bryn tenant name}-results</code>. Once you click on the bucket you should see a page like this:</p> <p></p> <p>There will be up to two types of file present in this S3 bucket; result JSON files and linkage JSON files.</p> <ul> <li>Result JSON files are named with the following pattern: <code>{project}.{run_index}.{run_id}.result.json</code> and contain all the relevant information about your sample including errors during the ingest process, issues with the metadata CSV, etc.</li> <li>Linkage JSON files are named with the following pattern: <code>{project}.{run_index}.{run_id}.linkage.json</code>, these are only generated once when the ingest for that run_index and run_id has been successful and the artifact has been ingested into the dataset. It contains data which can be used to link the submitted file names with the anonymised identifiers in the main dataset, you are responsible for maintaining this linkage information and have the ability to delete it from your results bucket, if you do and lose linkage we WILL NOT be able to establish linkage for you. </li> </ul> <p>To find the result for a specific artifact you can search, the search function requires a full match from the start of the file name, e.g. for a file named <code>synthscape.1.some_run_id.result.json</code></p> <ul> <li><code>1.some_run_id</code> will not match the file</li> <li><code>synthscape.1.some_run_id</code> will match the file</li> </ul> <p></p> <p>Once you have found the result / linkage file you are interested in you can download it by clicking on it, be aware, these files contain private identifiers and should be treated as sensitive, we take no responsibility if you do not follow data security procedures for your trust / organisation.</p> <p>A result JSON will look similar to this:</p> <pre><code>{\n  \"uuid\": \"f84ae65d-ec57-443a-946f-6af34bace889\",\n  \"site\": \"synthscape\",\n  \"raw_site\": \"synthscape.ukhsa\",\n  \"uploaders\": [\n    \"bryn-synthscape-ukhsa\"\n  ],\n  \"match_timestamp\": 1.7286538918609505e+18,\n  \"artifact\": \"synthscape|0|183c4a97-d269-4014-9304-9b1f840cd0cd\",\n  \"run_index\": \"0\",\n  \"run_id\": \"183c4a97-d269-4014-9304-9b1f840cd0cd\",\n  \"project\": \"synthscape\",\n  \"platform\": \"ont\",\n  \"files\": {\n    \".csv\": {\n      \"uri\": \"s3://synthscape-synthscape.ukhsa-ont-prod/synthscape.0.183c4a97-d269-4014-9304-9b1f840cd0cd.csv\",\n      \"etag\": \"0b17ccec938f4876029972c4d37dba72\",\n      \"key\": \"synthscape.0.183c4a97-d269-4014-9304-9b1f840cd0cd.csv\",\n      \"submitter\": \"bryn-synthscape-ukhsa\",\n      \"parsed_fname\": {\n        \"project\": \"synthscape\",\n        \"run_index\": \"0\",\n        \"run_id\": \"183c4a97-d269-4014-9304-9b1f840cd0cd\",\n        \"ftype\": \"csv\"\n      }\n    },\n    \".fastq.gz\": {\n      \"uri\": \"s3://synthscape-synthscape.ukhsa-ont-prod/synthscape.0.183c4a97-d269-4014-9304-9b1f840cd0cd.fastq.gz\",\n      \"etag\": \"62adfae7ac5dcbcc3a770133e2bcf7e5\",\n      \"key\": \"synthscape.0.183c4a97-d269-4014-9304-9b1f840cd0cd.fastq.gz\",\n      \"submitter\": \"bryn-synthscape-ukhsa\",\n      \"parsed_fname\": {\n        \"project\": \"synthscape\",\n        \"run_index\": \"0\",\n        \"run_id\": \"183c4a97-d269-4014-9304-9b1f840cd0cd\",\n        \"ftype\": \"fastq\",\n        \"gzip\": \"gz\"\n      }\n    }\n  },\n  \"test_flag\": false,\n  \"validate\": false,\n  \"onyx_test_create_errors\": {\n    \"source_climb_id\": [\n      \"This CLIMB ID does not exist in mSCAPE.\"\n    ]\n  }\n}\n</code></pre> <p>If the submission was successful there will be no <code>onyx_test_create_errors</code> or <code>ingest_errors</code> fields present and the <code>created</code> / <code>published</code> fields will both be \"true\".</p> <p>Any metadata issues will be defined in the <code>onyx_test_create_errors</code> field separated by the field to which the issue applies, we hope that the errors should be fairly readable and self explanatory but if not the please contact the CLIMB-TRE team for assistance.</p>"},{"location":"synthscape-analysis/","title":"synthSCAPE Analysis Specification","text":""},{"location":"synthscape-analysis/#analysis-fields","title":"Analysis fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>published_date</code> <code>date</code> The date the object was published in Onyx. \u2022 Output format: <code>iso-8601</code> <code>site</code> <code>choice</code> The site or sequencing centre providing the data. \u2022 Choices: <code>bham</code>, <code>synthscape</code>, <code>ukhsa</code> <code>climb_id</code> <code>text</code> Unique identifier for a project record in Onyx. <code>biosample_id</code> <code>text</code> The sequencing provider's identifier for a sample. <code>biosample_source_id</code> <code>text</code> Unique identifier for an individual to permit multiple samples from the same individual to be linked. <code>run_id</code> <code>text</code> Unique identifier assigned to the run by the sequencing instrument. <code>platform</code> <code>choice</code> The platform used to sequence the data. \u2022 Choices: <code>illumina</code>, <code>illumina.se</code>, <code>ont</code> <code>input_type</code> <code>choice</code> The type of input sequenced. \u2022 Choices: <code>community_standard</code>, <code>negative_control</code>, <code>positive_control</code>, <code>specimen</code>, <code>validation_material</code> <code>specimen_type_details</code> <code>choice</code> Named control or standard for specimens. \u2022 Choices: <code>asymptomatic</code>, <code>respiratory_infection</code> <code>control_type_details</code> <code>choice</code> Named control or standard for positive and negative controls. \u2022 Choices: <code>NIBSC_11/242</code>, <code>NIBSC_20/170</code>, <code>bacillus_ms2phage</code>, <code>resp_matrix_mc110</code>, <code>water_extraction_control</code>, <code>zepto_rp2.1</code>, <code>zymo-mc_D6300</code> <code>sample_source</code> <code>choice</code> The source from which the sample was collected. \u2022 Choices: <code>blood</code>, <code>environment</code>, <code>faecal</code>, <code>lower_respiratory</code>, <code>nose_and_throat</code>, <code>other</code>, <code>plasma</code>, <code>pleural_fluid</code>, <code>stool</code>, <code>tissue</code>, <code>upper_respiratory</code>, <code>urine</code> <code>sample_type</code> <code>choice</code> The type of sampling method used. \u2022 Choices: <code>aspirate</code>, <code>bal</code>, <code>biopsy</code>, <code>other</code>, <code>sputum</code>, <code>swab</code> <code>spike_in</code> <code>choice</code> The type of spike-in used in the run. \u2022 Choices: <code>ERCC-RNA_4456740</code>, <code>bacillus_ms2phage</code>, <code>ms2-phage</code>, <code>none</code>, <code>phix</code>, <code>tobacco_mosaic_virus</code>, <code>zymo_D6320</code>, <code>zymo_D6321</code> <code>spike_in_result</code> <code>choice</code> Result assigned by scylla for the provided spike-in. \u2022 Choices: <code>fail</code>, <code>partial</code>, <code>pass</code> <code>collection_date</code> <code>date</code> The date the sample was collected. \u2022 Output format: <code>YYYY-MM-DD</code> <code>received_date</code> <code>date</code> The date the sample was received by the sequencing centre (if collection_date unavailable). \u2022 Output format: <code>YYYY-MM-DD</code> <code>is_approximate_date</code> <code>bool</code> The date is approximate e.g. the sample is from a public repository and it is unclear whether the date corresponds to collection or publishing. <code>batch_id</code> <code>text</code> Used to identify samples prepared in the same laboratory batch (e.g. extraction, library and/or sequencing). <code>study_id</code> <code>text</code> Used to identify study or if NHS residual sample. <code>study_centre_id</code> <code>text</code> Used to identify sequencing centre. <code>sequence_purpose</code> <code>choice</code> Used to differentiate between clinical or research studies. \u2022 Choices: <code>clinical</code>, <code>research</code> <code>governance_status</code> <code>choice</code> Did the patient consent to their sample being used for research purposes or not. \u2022 Choices: <code>consented_for_research</code>, <code>no_consent_for_research</code>, <code>open</code> <code>iso_country</code> <code>choice</code> Country that the sample was collected in, using ISO-3166-1 alpha-2 codes (https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2), unless within United Kingdom. If so, use ISO-3166-2:GB (https://en.wikipedia.org/wiki/ISO_3166-2:GB). \u2022 Choices: <code>AD</code>, <code>AE</code>, <code>AF</code>, <code>AG</code>, <code>AI</code>, <code>AL</code>, <code>AM</code>, <code>AO</code>, <code>AQ</code>, <code>AR</code>, <code>AS</code>, <code>AT</code>, <code>AU</code>, <code>AW</code>, <code>AX</code>, <code>AZ</code>, <code>BA</code>, <code>BB</code>, <code>BD</code>, <code>BE</code>, ... <code>iso_region</code> <code>choice</code> Region that the sample was collected in, using the second level subdivision codes of ISO-3166-2:GB (https://www.iso.org/obp/ui/#iso:code:3166:GB). \u2022 Choices: <code>GB-ABC</code>, <code>GB-ABD</code>, <code>GB-ABE</code>, <code>GB-AGB</code>, <code>GB-AGY</code>, <code>GB-AND</code>, <code>GB-ANN</code>, <code>GB-ANS</code>, <code>GB-BAS</code>, <code>GB-BBD</code>, <code>GB-BCP</code>, <code>GB-BDF</code>, <code>GB-BDG</code>, <code>GB-BEN</code>, <code>GB-BEX</code>, <code>GB-BFS</code>, <code>GB-BGE</code>, <code>GB-BGW</code>, <code>GB-BIR</code>, <code>GB-BKM</code>, ... <code>extraction_enrichment_protocol</code> <code>text</code> Details of nucleic acid extraction and optional enrichment steps. <code>library_protocol</code> <code>text</code> Details of sequencing library construction. <code>sequencing_protocol</code> <code>text</code> Details of sequencing. <code>protocol_arm</code> <code>choice</code> Used to indicate arm for protocols which have separate arms for bacterial and viral nucleic acids. \u2022 Choices: <code>bacterial</code>, <code>viral</code> <code>bioinformatics_protocol</code> <code>text</code> Detail of initial bioinformatics protocol, for example versions of basecalling software and models used, any read quality filtering/trimming employed. <code>dehumanisation_protocol</code> <code>text</code> Details of bioinformatics method used for human read removal. <code>is_public_dataset</code> <code>bool</code> The sample is from a public dataset. Please only set this after it has been made public. <code>public_database_name</code> <code>choice</code> The public repository where the data is. \u2022 Choices: <code>ENA</code>, <code>SRA</code> <code>public_database_accession</code> <code>text</code> The accession for the data in the public database. <code>ingest_report</code> <code>text</code> HTML report summarising the read profile and taxa identified. <code>taxon_reports</code> <code>text</code> Folder of all classification output files. <code>human_filtered_reads_1</code> <code>text</code> Compressed FASTQ of input reads that have been filtered for human reads. <code>human_filtered_reads_2</code> <code>text</code> Compressed FASTQ of input reads that have been filtered for human reads. <code>unclassified_reads_1</code> <code>text</code> Compressed FASTQ of input reads which could not be classified. <code>unclassified_reads_2</code> <code>text</code> Compressed FASTQ of input reads which could not be classified. <code>viral_reads_1</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral. <code>viral_reads_2</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral. <code>viral_and_unclassified_reads_1</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral or were unclassified. <code>viral_and_unclassified_reads_2</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral or were unclassified. <code>total_bases</code> <code>integer</code> Total number of bases in the input FASTQ file(s), before any filtering. <code>classifier</code> <code>choice</code> The classifier used. \u2022 Choices: <code>Kraken2</code> <code>classifier_version</code> <code>text</code> Version of the classifier used. <code>classifier_db</code> <code>choice</code> Database used for read classification. \u2022 Choices: <code>PlusPF</code> <code>classifier_db_date</code> <code>date</code> Date classifier database was produced. \u2022 Output format: <code>YYYY-MM-DD</code> <code>ncbi_taxonomy_date</code> <code>date</code> Date that the NCBI taxonomy dump was produced. \u2022 Output format: <code>YYYY-MM-DD</code> <code>scylla_version</code> <code>text</code> Version of the scylla pipeline used. <code>chimera_bam</code> <code>text</code> BAM file of the human filtered read fraction aligned to the zeus database. <code>is_chimera_published</code> <code>bool</code> Whether chimera has been run on this record or not. <code>alignment_db_version</code> <code>text</code> Version of the Zeus database used. <code>sylph_db_version</code> <code>text</code> Sylph database version utilised to produce Sylph classifications. <code>source_climb_id</code> <code>text</code> CLIMB ID of the record used as a base dataset. <code>spiked_ids</code> <code>array</code> JSON list of taxon ids included in the spike-in. \u2022 Array type: <code>integer</code> <code>applications</code> <code>array</code> JSON list of applications. \u2022 Array type: <code>text</code> <code>methods</code> <code>structure</code> JSON dictionary containing methods. <code>taxa_files</code> <code>relation</code> Table of all species level taxa extracted by the Scylla ingest pipeline. <code>taxa_files.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>taxa_files.human_readable</code> <code>text</code> A human readable name for the taxa. <code>taxa_files.n_reads</code> <code>integer</code> The number of reads extracted for the taxa. <code>taxa_files.total_bases</code> <code>integer</code> Total number of bases extracted for the taxa. <code>taxa_files.avg_quality</code> <code>decimal</code> The mean quality of reads extracted for the taxa. <code>taxa_files.mean_len</code> <code>decimal</code> The mean length of reads extracted for the taxa. <code>taxa_files.rank</code> <code>choice</code> The rank of the taxa. \u2022 Choices: <code>C</code>, <code>D</code>, <code>F</code>, <code>G</code>, <code>K</code>, <code>O</code>, <code>P</code>, <code>R</code>, <code>S</code>, <code>U</code> <code>taxa_files.fastq_1</code> <code>text</code> Compressed FASTQ of extracted reads for the taxa. <code>taxa_files.fastq_2</code> <code>text</code> Compressed FASTQ of extracted reads for the taxa. <code>classifier_calls</code> <code>relation</code> Table summarising the NCBI taxonomy ids, counts and ranks of all taxa found by the classifier during the Scylla ingest pipeline. <code>classifier_calls.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>classifier_calls.human_readable</code> <code>text</code> A human readable name for the taxa. <code>classifier_calls.percentage</code> <code>decimal</code> The percentage of the (dehumanised) sample that the taxa represents. <code>classifier_calls.count_descendants</code> <code>integer</code> The number of reads mapping to this taxa and all descendant taxa. <code>classifier_calls.count_direct</code> <code>integer</code> The number of reads mapping directly to the taxa. <code>classifier_calls.rank</code> <code>choice</code> The rank of the taxa. \u2022 Choices: <code>C</code>, <code>D</code>, <code>F</code>, <code>G</code>, <code>K</code>, <code>O</code>, <code>P</code>, <code>R</code>, <code>S</code>, <code>U</code> <code>classifier_calls.raw_rank</code> <code>text</code> The rank of the taxa including an intermediate grading. <code>classifier_calls.is_spike_in</code> <code>bool</code> The taxa is a spike-in. <code>spike_in_info</code> <code>relation</code> Table containing results found for the provided spike-in. <code>spike_in_info.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>spike_in_info.human_readable</code> <code>text</code> A human readable name for the taxa. <code>spike_in_info.reference_header</code> <code>text</code> Reference header for the individual sequence within the provided spike-in. <code>spike_in_info.mapped_count</code> <code>integer</code> Number of reads which aligned to a reference sequence for the provided spike-in. <code>alignment_results</code> <code>relation</code> Table containing alignment results from the viral alignment stage of the CLIMB-TRE/chimera pipeline. <code>alignment_results.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>alignment_results.human_readable</code> <code>text</code> Human readable scientific name for the taxa. <code>alignment_results.unique_accession</code> <code>text</code> Unique reference identifier in the alignment database (everything prior to the first whitespace in the FASTA header). <code>alignment_results.accession_description</code> <code>text</code> The comment for the reference sequence within the alignment database. <code>alignment_results.sequence_length</code> <code>integer</code> Length of the reference sequence in the alignment database. <code>alignment_results.evenness_value</code> <code>integer</code> A percentage indicating how evenly read depths are distributed throughout the reference, with 0 being completely uneven, and 100 being perfectly even. Taken from https://academic.oup.com/nar/article/38/10/e116/2902812, under the \u201cCalculation of evenness score\u201d section, and calculated here: https://github.com/CLIMB-TRE/chimera/blob/dca3cacb949dabc902d0a12e5d11d36c6ac555fd/bin/generate_alignment_report.py#L102. <code>alignment_results.mean_depth</code> <code>integer</code> Mean of all depth values across the alignment reference. <code>alignment_results.coverage_1x</code> <code>integer</code> Percentage of the reference sequence covered with a depth of at least 1x. <code>alignment_results.coverage_10x</code> <code>integer</code> Percentage of the reference covered with a depth of at least 10x. <code>alignment_results.mapped_reads</code> <code>integer</code> Total number of reads mapped to the alignment reference. <code>alignment_results.uniquely_mapped_reads</code> <code>integer</code> Total number of reads which uniquely map to each reference sequence, calculated for each reference sequence here: https://github.com/CLIMB-TRE/chimera/blob/bca6fe6fe293f8e56d9e70627a846dda6f3d886a/bin/generate_alignment_report.py#L59-L82. <code>alignment_results.mapped_bases</code> <code>integer</code> Approximation for the total number of bases mapped to the alignment reference, calculated from the length of the reference sequence multiplied by the mean depth of alignments to that reference. <code>alignment_results.mean_read_identity</code> <code>decimal</code> Mean of read identities across all alignments. Can be considered an approximation for identity of the source genome with the reference sequence. Calculated for each read here: https://github.com/CLIMB-TRE/chimera/blob/dca3cacb949dabc902d0a12e5d11d36c6ac555fd/bin/generate_alignment_report.py#L58 <code>alignment_results.read_duplication_rate</code> <code>decimal</code> What proportion of the reads start and end in the same alignment reference position as at least one other read within the alignment. Calculated here: https://github.com/CLIMB-TRE/chimera/blob/dca3cacb949dabc902d0a12e5d11d36c6ac555fd/bin/generate_alignment_report.py#L76-L83 <code>alignment_results.forward_proportion</code> <code>decimal</code> Proportion of reads which aligned to the forward strand. Between 0 and 1, with 0 indicating all reads aligned to the reverse strand, 1 the opposite. True hits should be close to 0.5 for this value for any reasonable mean depth. <code>alignment_results.mean_alignment_length</code> <code>decimal</code> Mean length of all alignments to the reference - different to mean read length aligned to the reference, since it only considers the aligned section of the reads. <code>sylph_results</code> <code>relation</code> Table containing sylph results from the Sylph classification stage of the CLIMB-TRE/chimera pipeline. <code>sylph_results.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>sylph_results.human_readable</code> <code>text</code> Human readable scientific name for the taxa. <code>sylph_results.gtdb_taxon_string</code> <code>text</code> Description of the taxonomic placement of the source contig within the Sylph database using GTDBs taxon string format. <code>sylph_results.gtdb_assembly_id</code> <code>text</code> Assembly ID (often genbank accession) for the contig within the sylph database, taken from GTDB. <code>sylph_results.gtdb_contig_header</code> <code>text</code> From the origin FASTA record header as it appears in GTDB. Identical to 'Contig_name' field in sylph profile output. <code>sylph_results.taxonomic_abundance</code> <code>decimal</code> Normalized taxonomic abundance as a percentage. Identical to 'Taxonomic_abundance' in sylph profile output. <code>sylph_results.sequence_abundance</code> <code>decimal</code> Normalized sequence abundance as a percentage. Identical to 'Sequence_abundance' in sylph profile output. <code>sylph_results.adjusted_ani</code> <code>decimal</code> If coverage adjustment is possible (cov is &lt; 3x cov): returns coverage-adjusted ANI (Average Nucleotide Identity). If coverage is too low/high: returns naive_ani. Identical to 'Adjusted_ANI' in sylph profile output. <code>sylph_results.ani_confidence_interval</code> <code>text</code> [5%,95%] confidence intervals. If coverage adjustment is possible: float-float e.g. 98.52-99.55. If coverage is too low/high: NA-NA is given. Identical to 'ANI_5-95_percentile' field in sylph profile output. <code>sylph_results.effective_coverage</code> <code>decimal</code> Estimated '\u03bbeff' value, true value is not calculated, this is estimated based on kmers. More information is available in the sylph paper: https://www.nature.com/articles/s41587-024-02412-y. If coverage adjustment is possible, lambda estimate is given. Identical to 'Eff_cov' field in sylph profile output. <code>sylph_results.effective_coverage_confidence_interval</code> <code>text</code> [5%, 95%] confidence intervals for lambda. Same format rules as 'ani_confidence_interval'. Identical to 'Lambda_5-95_percentile' field in sylph profile output. <code>sylph_results.median_kmer_cov</code> <code>integer</code> Median k-mer multiplicity for k-mers with &gt;= 1 multiplicity. Identical to 'Median_cov' field in sylph profile output. <code>sylph_results.mean_kmer_cov</code> <code>decimal</code> Mean k-mer multiplicity for k-mers with &gt;= 1 multiplicity. Identical to 'Mean_cov_geq1' field in sylph profile output. <code>sylph_results.containment_index</code> <code>text</code> int/int showing the containment index (number of k-mers found in sample divided by total k-mers), e.g. 959/1053. Identical to 'Containment_ind' field in sylph profile output. <code>sylph_results.naive_ani</code> <code>decimal</code> Containment ANI without coverage adjustment. Identical to 'Naive_ANI' field in sylph profile output. <code>sylph_results.kmers_reassigned</code> <code>integer</code> The number of k-mers reassigned away from the genome. Identical to 'Kmers_reassigned' field in sylph profile output."},{"location":"synthscape/","title":"synthSCAPE Uploader Specification","text":""},{"location":"synthscape/#files-to-be-provided","title":"Files to be provided","text":"<p>For paired-end Illumina sequencing data, suppliers must provide:</p> <ul> <li>A FASTQ 1 file containing the forward sequencing reads.</li> <li>A FASTQ 2 file containing the reverse sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul> <p>For single-end Illumina sequencing data, suppliers must provide:</p> <ul> <li>A FASTQ file containing the sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul> <p>For ONT sequencing data, suppliers must provide:</p> <ul> <li>A FASTQ file containing the sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul> <p>Sequencing data must be dehumanised prior to submission. The ingest pipeline will reject sequencing data where the number of assigned human reads exceeds the human read rejection threshold.</p>"},{"location":"synthscape/#file-naming-convention","title":"File naming convention","text":"<p>The base filenames should be of the form</p> <pre><code>synthscape.[run_index].[run_id].[extension]\n</code></pre> <p>where:</p> <ul> <li><code>[run_index]</code> is an identifier that is unique within a sequencing run, e.g. a sequencing barcode identifier, or a 96-well plate co-ordinate.</li> <li><code>[run_id]</code> is the name of the sequencing run as given by the supplier's sequencing instrument (not an internal identifier assigned by the supplier).</li> <li><code>[extension]</code> is the file extension indicating the file type.</li> </ul>"},{"location":"synthscape/#file-name-extensions","title":"File name extensions","text":"<p>For paired-end Illumina sequencing data, the extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>1.fastq.gz</code> for the forward FASTQ file.</li> <li><code>2.fastq.gz</code> for the reverse FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul> <p>For single-end Illumina sequencing data, the extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>fastq.gz</code> for the forward FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul> <p>For ONT sequencing data, the extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>fastq.gz</code> for the forward FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul>"},{"location":"synthscape/#valid-characters","title":"Valid characters","text":"<p>The <code>[run_index]</code>, <code>[run_id]</code> and <code>[extension]</code> must contain only:</p> <ul> <li>Letters (<code>A-Z</code>, <code>a-z</code>).</li> <li>Numbers (<code>0-9</code>).</li> <li>Hyphens (<code>-</code>).</li> <li>Underscores (<code>_</code>).</li> </ul>"},{"location":"synthscape/#buckets","title":"Buckets","text":"<p>Bucket names follow the general convention:</p> <pre><code>synthscape-[sequencing_org]-[platform]-[test_flag]\n</code></pre>"},{"location":"synthscape/#metadata-specification","title":"Metadata specification","text":""},{"location":"synthscape/#csv-template","title":"CSV Template","text":"<p>A CSV template for uploaders can be downloaded here: synthscape-template.csv</p>"},{"location":"synthscape/#required-fields","title":"Required fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>biosample_id</code> <code>text</code> The sequencing provider's identifier for a sample. \u2022 Max length: <code>50</code> <code>run_index</code> <code>text</code> The sequencing provider's identifier for the position of a sample on a run. \u2022 Max length: <code>50</code> <code>run_id</code> <code>text</code> Unique identifier assigned to the run by the sequencing instrument. \u2022 Max length: <code>100</code> <code>input_type</code> <code>choice</code> The type of input sequenced. \u2022 Choices: <code>community_standard</code>, <code>negative_control</code>, <code>positive_control</code>, <code>specimen</code>, <code>validation_material</code> <code>sample_source</code> <code>choice</code> The source from which the sample was collected. \u2022 Choices: <code>blood</code>, <code>environment</code>, <code>faecal</code>, <code>lower_respiratory</code>, <code>nose_and_throat</code>, <code>other</code>, <code>plasma</code>, <code>pleural_fluid</code>, <code>stool</code>, <code>tissue</code>, <code>upper_respiratory</code>, <code>urine</code> <code>sample_type</code> <code>choice</code> The type of sampling method used. \u2022 Choices: <code>aspirate</code>, <code>bal</code>, <code>biopsy</code>, <code>other</code>, <code>sputum</code>, <code>swab</code> <code>spike_in</code> <code>choice</code> The type of spike-in used in the run. \u2022 Choices: <code>ERCC-RNA_4456740</code>, <code>bacillus_ms2phage</code>, <code>ms2-phage</code>, <code>none</code>, <code>phix</code>, <code>tobacco_mosaic_virus</code>, <code>zymo_D6320</code>, <code>zymo_D6321</code> <p>At least one of the following fields are required:</p> Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>collection_date</code> <code>date</code> The date the sample was collected. \u2022 Input formats: <code>YYYY-MM</code>, <code>YYYY-MM-DD</code>\u2022 Output format: <code>YYYY-MM-DD</code> <code>received_date</code> <code>date</code> The date the sample was received by the sequencing centre (if collection_date unavailable). \u2022 Input formats: <code>YYYY-MM</code>, <code>YYYY-MM-DD</code>\u2022 Output format: <code>YYYY-MM-DD</code>"},{"location":"synthscape/#optional-fields","title":"Optional fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>biosample_source_id</code> <code>text</code> Unique identifier for an individual to permit multiple samples from the same individual to be linked. \u2022 Max length: <code>50</code> <code>specimen_type_details</code> <code>choice</code> Named control or standard for specimens. \u2022 Required when <code>input_type</code> is: <code>specimen</code>\u2022 Choices: <code>asymptomatic</code>, <code>respiratory_infection</code> <code>control_type_details</code> <code>choice</code> Named control or standard for positive and negative controls. \u2022 Required when <code>input_type</code> is: <code>positive_control</code>\u2022 Required when <code>input_type</code> is: <code>negative_control</code>\u2022 Choices: <code>NIBSC_11/242</code>, <code>NIBSC_20/170</code>, <code>bacillus_ms2phage</code>, <code>resp_matrix_mc110</code>, <code>water_extraction_control</code>, <code>zepto_rp2.1</code>, <code>zymo-mc_D6300</code> <code>is_approximate_date</code> <code>bool</code> The date is approximate e.g. the sample is from a public repository and it is unclear whether the date corresponds to collection or publishing. \u2022 Default: <code>False</code> <code>batch_id</code> <code>text</code> Used to identify samples prepared in the same laboratory batch (e.g. extraction, library and/or sequencing). \u2022 Max length: <code>100</code> <code>study_id</code> <code>text</code> Used to identify study or if NHS residual sample. \u2022 Max length: <code>100</code> <code>study_centre_id</code> <code>text</code> Used to identify sequencing centre. \u2022 Max length: <code>100</code> <code>sequence_purpose</code> <code>choice</code> Used to differentiate between clinical or research studies. \u2022 Choices: <code>clinical</code>, <code>research</code> <code>governance_status</code> <code>choice</code> Did the patient consent to their sample being used for research purposes or not. \u2022 Default: <code>no_consent_for_research</code>\u2022 Choices: <code>consented_for_research</code>, <code>no_consent_for_research</code>, <code>open</code> <code>iso_country</code> <code>choice</code> Country that the sample was collected in, using ISO-3166-1 alpha-2 codes (https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2), unless within United Kingdom. If so, use ISO-3166-2:GB (https://en.wikipedia.org/wiki/ISO_3166-2:GB). \u2022 Choices: <code>AD</code>, <code>AE</code>, <code>AF</code>, <code>AG</code>, <code>AI</code>, <code>AL</code>, <code>AM</code>, <code>AO</code>, <code>AQ</code>, <code>AR</code>, <code>AS</code>, <code>AT</code>, <code>AU</code>, <code>AW</code>, <code>AX</code>, <code>AZ</code>, <code>BA</code>, <code>BB</code>, <code>BD</code>, <code>BE</code>, ... <code>iso_region</code> <code>choice</code> Region that the sample was collected in, using the second level subdivision codes of ISO-3166-2:GB (https://www.iso.org/obp/ui/#iso:code:3166:GB). \u2022 Requires: <code>iso_country</code>\u2022 Choices: <code>GB-ABC</code>, <code>GB-ABD</code>, <code>GB-ABE</code>, <code>GB-AGB</code>, <code>GB-AGY</code>, <code>GB-AND</code>, <code>GB-ANN</code>, <code>GB-ANS</code>, <code>GB-BAS</code>, <code>GB-BBD</code>, <code>GB-BCP</code>, <code>GB-BDF</code>, <code>GB-BDG</code>, <code>GB-BEN</code>, <code>GB-BEX</code>, <code>GB-BFS</code>, <code>GB-BGE</code>, <code>GB-BGW</code>, <code>GB-BIR</code>, <code>GB-BKM</code>, ... <code>extraction_enrichment_protocol</code> <code>text</code> Details of nucleic acid extraction and optional enrichment steps. <code>library_protocol</code> <code>text</code> Details of sequencing library construction. <code>sequencing_protocol</code> <code>text</code> Details of sequencing. <code>protocol_arm</code> <code>choice</code> Used to indicate arm for protocols which have separate arms for bacterial and viral nucleic acids. \u2022 Choices: <code>bacterial</code>, <code>viral</code> <code>bioinformatics_protocol</code> <code>text</code> Detail of initial bioinformatics protocol, for example versions of basecalling software and models used, any read quality filtering/trimming employed. <code>dehumanisation_protocol</code> <code>text</code> Details of bioinformatics method used for human read removal. <code>is_public_dataset</code> <code>bool</code> The sample is from a public dataset. Please only set this after it has been made public. \u2022 Default: <code>False</code> <code>public_database_name</code> <code>choice</code> The public repository where the data is. \u2022 Choices: <code>ENA</code>, <code>SRA</code> <code>public_database_accession</code> <code>text</code> The accession for the data in the public database. <code>source_climb_id</code> <code>text</code> CLIMB ID of the record used as a base dataset. \u2022 Max length: <code>12</code> <code>spiked_ids</code> <code>array</code> JSON list of taxon ids included in the spike-in. \u2022 Default: <code>[]</code>\u2022 Array type: <code>integer</code> <code>applications</code> <code>array</code> JSON list of applications. \u2022 Default: <code>[]</code>\u2022 Array type: <code>text</code> <code>methods</code> <code>structure</code> JSON dictionary containing methods. \u2022 Default: <code>{}</code>"},{"location":"upload/","title":"Uploading data","text":""},{"location":"upload/#overview","title":"Overview","text":"<p>Data in CLIMB-TRE is managed through a database called Onyx. To upload data into Onyx, you must deposit the appropriate files (including the metadata) into the relevant S3 bucket on CLIMB. We recommend doing this using the AWS or <code>s3cmd</code> command-line tools. For general information about how to upload data to CLIMB, see the CLIMB docs on setting up <code>s3cmd</code> locally and running <code>s3cmd</code> locally or on Bryn. You may also wish to review the overall CLIMB storage documentation.</p> <p>Each CLIMB-TRE project requires data (e.g. FASTQ sequencing reads) and metadata (e.g. a CSV file).  These must match the relevant specification (\"spec\") and be uploaded to the appropriate S3 bucket.  Doing so will trigger the ingest process.  Data that doesn't meet the spec will not be ingested.</p> <p>Lines starting with <code>$</code> indicate commands to be entered at a terminal. The <code>$</code> represents the prompt, which might be different on your system.</p>"},{"location":"upload/#preparing-example-fastq-files","title":"Preparing example FASTQ files","text":"<p>As an example, let's imagine we want to upload the two example files in Conor Meehan's Pathogen genomics course as part of the mSCAPE project. The two files are from Hikichi et al. (2019), <code>DRR187559_1.fastqsanger.bz2</code> and <code>DRR187559_2.fastqsanger.bz2</code>, available in this Zenodo archive.  You can download the files either by clicking on them in the Zenodo interface or with the common command line tools <code>wget</code>: <pre><code>$ wget https://zenodo.org/record/4534098/files/DRR187559_1.fastqsanger.bz2\n$ wget https://zenodo.org/record/4534098/files/DRR187559_2.fastqsanger.bz2\n</code></pre> or <code>curl</code>: <pre><code>$ curl -L https://zenodo.org/record/4534098/files/DRR187559_1.fastqsanger.bz2 -O\n$ curl -L https://zenodo.org/record/4534098/files/DRR187559_2.fastqsanger.bz2 -O\n</code></pre></p> <p>These two files are bzip2 files, not gzip, which is what we need.  We can convert them by piping the output from <code>bzcat</code> (which decompresses the files) to <code>gzip -c</code> (which compresses the stream and writes it to <code>STDOUT</code>) and then to new files: <pre><code>$ bzcat DRR187559_1.fastqsanger.bz2 | gzip -c &gt; DRR187559_1.fastq.gz\n$ bzcat DRR187559_2.fastqsanger.bz2 | gzip -c &gt; DRR187559_2.fastq.gz\n</code></pre></p> <p>The mSCAPE specification says that our files must have names like <code>mscape.[run_index].[run_id].[extension]</code>, where the extension is <code>1.fastq.gz</code> or <code>2.fastq.gz</code>.  The <code>run_index</code> and <code>run_id</code> can in principle contain any alphanumeric characters, underscores (<code>_</code>) or hyphens ('-'), so you can rename the FASTQ files to whatever meets those requirements. At the command line, this means moving the files with something like: <pre><code>$ mv DRR187559_1.fastq.gz mscape.test-run-index-01.test-run-id-01.1.fastq.gz\n$ mv DRR187559_2.fastq.gz mscape.test-run-index-01.test-run-id-01.2.fastq.gz\n</code></pre></p>"},{"location":"upload/#creating-a-metadata-csv-file","title":"Creating a metadata CSV file","text":"<p>Data uploads require that the FASTQ files are accompanied by a CSV file with the metadata (e.g. when the sample was taken, what type of sample it is). This CSV file must have two rows:</p> <ol> <li>the headers, as in the project metadata specification; and</li> <li>the actual metadata.</li> </ol> <p>It's filename must match the FASTQ files but with the extension <code>csv</code> instead of <code>1.fastq.gz</code> or <code>2.fastq.gz</code> (or <code>fastq.gz</code> if your data is single ended).</p> <p>For the sake of our test and getting to know the system, you should try to create such a file by hand by referring to the relevant metadata spec. The columns are documented in alphabetical order but can be given in any order. The optional columns can be omitted entirely.</p> <p>Note that the <code>run_index</code> and <code>run_id</code> must exactly match the values implied by the FASTQ filenames.  E.g., in my example above</p> <ul> <li>the <code>run_index</code> is <code>test-run-index-01</code> and</li> <li>the <code>run_id</code> is <code>test-run-id-01</code>.</li> </ul> <p>The first few columns of your metadata CSV file might look like <pre><code>run_index,run_id,biosample_id,sample_source,sample_type,...\ntest-run-index-01,test-run-id-01,test-sample-01,nose_and_throat,swab,...\n</code></pre> with no extra spaces separating the fields.</p>"},{"location":"upload/#uploading-files-to-s3-buckets","title":"Uploading files to S3 buckets","text":"<p>You're now ready to upload your data to one of the buckets, which we'll do using the <code>s3cmd</code> tool. There's more information about using <code>s3cmd</code> with Bryn in the CLIMB-BIG-DATA documentation on storage.</p> <p>You can download <code>s3cmd</code> from the <code>s3cmd</code> download pages or install it using <code>pip</code> (perhaps in a virtual or Conda environment) with <pre><code>$ python3 -m pip install s3cmd\n</code></pre> To set <code>s3cmd</code> up to communicate with the buckets, you'll need your API keys from Bryn.  You can find them by logging in to Bryn, selecting the S3 Buckets tab on the left and click the Show API Keys button that appears below the list of buckets.</p> <p>You can then set up <code>s3cmd</code> with <pre><code>$ s3cmd --configure\n</code></pre> When asked for the following, you should give these answers:</p> <ul> <li>Access Key: value of <code>AWS_ACCESS_KEY_ID</code> displayed on Bryn.</li> <li>Secret Key: value of <code>AWS_SECRET_ACCESS_KEY</code> displayed on Bryn.</li> <li>Default Region [US]: leave blank.</li> <li>S3 Endpoint: <code>s3.climb.ac.uk</code></li> <li>DNS-style bucket+hostname:port template for accessing a bucket: <code>%(bucket)s.s3.climb.ac.uk</code></li> </ul> <p>You now should be ready to upload the data.  But where? The names of the S3 buckets for each project are given in the metadata specs but are usually of the form <pre><code>[project]-[sequencing_org]-[platform]-[test_flag]\n</code></pre> We'll use <code>mscape-public-illumina-test</code>, so the command to \"put\" the three files in the bucket would be <pre><code>$ s3cmd put mscape.test-run-index-01.test-run-id-01.csv mscape.test-run-index-01.test-run-id-01.1.fastq.gz mscape.test-run-index-01.test-run-id-01.2.fastq.gz s3://mscape-public-illumina-test\n</code></pre> You should then see the progress of your upload (the files might be split into parts), after which you're back at the terminal.</p> <p>Now what?</p>"},{"location":"upload/#finding-the-result-of-your-upload","title":"Finding the result of your upload","text":"<p>You won't get any feedback from <code>s3cmd</code> about the progress of your data into Onyx.  When the data is received in the bucket, it announces the files to whoever is listening, which includes a program called Roz.  It then starts to check the data: Are all the files present? Are they named correctly?  Is the metadata well-formed?  If so, the data is copied into internal project buckets and a record is added to the database, Onyx.</p> <p>At this point, you can interact with your data through Onyx, which is described in the page on analysing data in Onyx.</p>"}]}